{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nhgowtham/hackathon_gg/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset STO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "from tifffile import imread\n",
        "\n",
        "# === Settings ===\n",
        "ROOT_DIR = \"/home/gowthamnh/hackathon_gg/data/image_data\"\n",
        "DATASETS = {\n",
        "    \"cdte_dataset.h5\": \"DataSet_CdTe\",\n",
        "    \"sto_dataset.h5\": \"DataSet_STO\"\n",
        "}\n",
        "N_PREVIEW = 5  # For visual inspection\n",
        "\n",
        "# === Utils ===\n",
        "def normalize_percentile(img, pmin=2, pmax=98):\n",
        "    lo, hi = np.percentile(img, (pmin, pmax))\n",
        "    return np.clip((img - lo) / (hi - lo), 0, 1)\n",
        "\n",
        "def extract_label(fname):\n",
        "    return os.path.basename(fname).split(\"_\")[0].lower()\n",
        "\n",
        "def find_all_tif_files(folder):\n",
        "    tif_files = []\n",
        "    for root, _, files in os.walk(folder):\n",
        "        for file in files:\n",
        "            if file.endswith(\".tif\"):\n",
        "                tif_files.append(os.path.join(root, file))\n",
        "    return tif_files\n",
        "\n",
        "# === Core Processing ===\n",
        "def process_dataset(out_h5, subfolder):\n",
        "    input_dir = os.path.join(ROOT_DIR, subfolder)\n",
        "    all_files = find_all_tif_files(input_dir)\n",
        "    print(f\"ðŸ“ Processing {subfolder} ({len(all_files)} images)\")\n",
        "\n",
        "    label_map = {}\n",
        "    key_list = []\n",
        "    previews = []\n",
        "\n",
        "    with h5py.File(out_h5, \"w\") as f:\n",
        "        image_group = f.create_group(\"images\")\n",
        "        label_ds = f.create_group(\"labels\")\n",
        "\n",
        "        for path in all_files:\n",
        "            try:\n",
        "                raw = imread(path)\n",
        "                if raw.ndim > 2:\n",
        "                    raw = raw[..., 0]\n",
        "                raw = np.squeeze(raw).astype(np.float32)\n",
        "                norm = normalize_percentile(raw)\n",
        "\n",
        "                fname = os.path.basename(path)\n",
        "                label = extract_label(fname)\n",
        "                key = os.path.splitext(fname)[0].lower()\n",
        "\n",
        "                # Avoid duplicates\n",
        "                if key in image_group:\n",
        "                    i = 1\n",
        "                    while f\"{key}_{i}\" in image_group:\n",
        "                        i += 1\n",
        "                    key = f\"{key}_{i}\"\n",
        "\n",
        "                image_group.create_dataset(key, data=norm, compression=\"gzip\")\n",
        "                label_ds.attrs[key] = label\n",
        "                key_list.append(key)\n",
        "\n",
        "                label_map[label] = label_map.get(label, 0) + 1\n",
        "\n",
        "                if len(previews) < N_PREVIEW:\n",
        "                    previews.append((raw, norm, label, fname))\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"[ERROR] {path}: {e}\")\n",
        "\n",
        "        f.create_dataset(\"image_keys\", data=np.array(key_list, dtype='S'))\n",
        "\n",
        "    print(f\"âœ… Saved to {out_h5}\")\n",
        "    print(\"ðŸ“Š Label summary:\", label_map)\n",
        "    return previews\n",
        "\n",
        "# === Plot ===\n",
        "def plot_previews(previews, title):\n",
        "    fig, axs = plt.subplots(len(previews), 2, figsize=(6, 2 * len(previews)))\n",
        "    for i, (raw, norm, label, fname) in enumerate(previews):\n",
        "        axs[i, 0].imshow(raw, cmap='viridis')\n",
        "        axs[i, 0].set_title(f\"Original - {fname}\")\n",
        "        axs[i, 1].imshow(norm, cmap='viridis')\n",
        "        axs[i, 1].set_title(f\"Normalized - label: {label}\")\n",
        "    fig.suptitle(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# === Execute ===\n",
        "for out_file, folder in DATASETS.items():\n",
        "    previews = process_dataset(out_file, folder)\n",
        "    plot_previews(previews, f\"Preview from {out_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "found 764 files; labels=['Bulk', 'Extra', 'IExtra', 'Mis']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 764/764 [00:00<00:00, 2087.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wrote sto_dataset.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import pathlib, re, h5py, numpy as np, tifffile as tiff\n",
        "from tqdm import tqdm\n",
        "\n",
        "sto_root = pathlib.Path(\"data/image_data/DataSet_STO\")  # 64x64 tif patches; label prefix in filename\n",
        "h5_out = pathlib.Path(\"sto_dataset.h5\")\n",
        "label_regex = re.compile(r\"^([A-Za-z0-9]+)_\")  # prefix before first underscore\n",
        "\n",
        "def collect_files(root: pathlib.Path):\n",
        "    files = sorted([p for p in root.rglob(\"*.tif\")])\n",
        "    recs = []\n",
        "    for p in files:\n",
        "        m = label_regex.match(p.name)\n",
        "        if not m:\n",
        "            continue\n",
        "        recs.append({\"path\": p, \"label\": m.group(1)})\n",
        "    return recs\n",
        "\n",
        "records = collect_files(sto_root)\n",
        "labels = sorted({r[\"label\"] for r in records})\n",
        "label_to_id = {l: i for i, l in enumerate(labels)}\n",
        "print(f\"found {len(records)} files; labels={labels}\")\n",
        "\n",
        "with h5py.File(h5_out, \"w\") as f:\n",
        "    images_ds = f.create_dataset(\"images\", shape=(len(records), 64, 64), dtype=\"float32\")\n",
        "    labels_ds = f.create_dataset(\"labels\", shape=(len(records),), dtype=\"int32\")\n",
        "    paths_ds = f.create_dataset(\"meta/paths\", shape=(len(records),), dtype=h5py.string_dtype())\n",
        "    label_names_ds = f.create_dataset(\"meta/label_names\", data=np.array(labels, dtype=\"S\"))\n",
        "    for i, rec in enumerate(tqdm(records)):\n",
        "        img = tiff.imread(rec[\"path\"])\n",
        "        if img.ndim == 3:\n",
        "            img = img[..., 0]\n",
        "        images_ds[i] = img.astype(\"float32\")\n",
        "        labels_ds[i] = label_to_id[rec[\"label\"]]\n",
        "        paths_ds[i] = str(rec[\"path\"].relative_to(sto_root))\n",
        "print(\"wrote\", h5_out)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Atom finding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[idx=0] label=Bulk lat=15.08px r_assign=6.79px peaks=20 expected=18 missing_sites=0 extras=0 inter=0\n",
            "[idx=300] label=Extra lat=15.08px r_assign=6.79px peaks=21 expected=18 missing_sites=0 extras=0 inter=0\n",
            "[idx=500] label=IExtra lat=15.08px r_assign=6.79px peaks=20 expected=18 missing_sites=0 extras=2 inter=0\n",
            "[idx=762] label=Mis lat=15.08px r_assign=6.79px peaks=21 expected=18 missing_sites=0 extras=0 inter=0\n",
            "Saved: mask_outputs/sto_4case_masks.h5\n",
            "PNG debug outputs in: mask_outputs\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import h5py, numpy as np, matplotlib.pyplot as plt\n",
        "from skimage.restoration import denoise_tv_chambolle\n",
        "from skimage.filters import difference_of_gaussians\n",
        "from skimage.feature import peak_local_max\n",
        "from skimage.segmentation import watershed\n",
        "from scipy.spatial import cKDTree\n",
        "\n",
        "# =========================\n",
        "# CONFIG\n",
        "# =========================\n",
        "H5_IN = \"sto_dataset.h5\"\n",
        "OUT_DIR = \"mask_outputs\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# indices you requested\n",
        "CASE_IDXS = [0, 300, 500, 762]\n",
        "\n",
        "# if you want label-aware interstitial gating, set this True\n",
        "USE_LABELS_FROM_H5 = True\n",
        "\n",
        "# base params (use the same defaults you had)\n",
        "denoise_weight = 0.30\n",
        "dog_sigma1, dog_sigma2 = 0.6, 3.0\n",
        "peak_min_dist = 3\n",
        "peak_thr_k = 0.5\n",
        "\n",
        "use_watershed = True\n",
        "\n",
        "# IMPORTANT: keep assign_radius, but also provide an option to auto-scale from lattice spacing\n",
        "USE_AUTO_ASSIGN = True         # recommended\n",
        "ASSIGN_MULT = 0.45             # r_assign = ASSIGN_MULT * lattice_spacing\n",
        "assign_radius_fallback = 10.0  # used only if auto fails\n",
        "\n",
        "fft_peak_exclude = 3\n",
        "fft_topk = 12\n",
        "fft_min_dist = 4\n",
        "fft_collinear_thresh = 0.93\n",
        "\n",
        "# semantic IDs\n",
        "ID2NAME = {0:\"bulk\", 1:\"missing\", 2:\"extra_atom\", 3:\"extra_interstitial\"}\n",
        "NAME2ID = {v:k for k,v in ID2NAME.items()}\n",
        "\n",
        "COLOR = {\n",
        "    \"bulk\":              np.array([0.0, 0.0, 0.0, 0.0]),\n",
        "    \"missing\":           np.array([0.2, 0.45, 1.0, 0.40]),\n",
        "    \"extra_atom\":        np.array([1.0, 0.1, 0.1, 0.55]),\n",
        "    \"extra_interstitial\":np.array([1.0, 0.9, 0.1, 0.55]),\n",
        "}\n",
        "\n",
        "# =========================\n",
        "# HELPERS\n",
        "# =========================\n",
        "def normalize01(img):\n",
        "    img = img.astype(np.float32)\n",
        "    p1, p99 = np.percentile(img, (1, 99))\n",
        "    return np.clip((img - p1) / (p99 - p1 + 1e-6), 0, 1)\n",
        "\n",
        "def locate_atoms(img, denoise_weight, dog_sigma1, dog_sigma2, peak_min_dist, peak_thr_k, use_watershed):\n",
        "    img = img.astype(np.float32)\n",
        "    imgz = (img - img.mean()) / (img.std() + 1e-6)\n",
        "\n",
        "    den = denoise_tv_chambolle(imgz, weight=denoise_weight)\n",
        "    band = difference_of_gaussians(den, dog_sigma1, dog_sigma2)\n",
        "\n",
        "    thr = float(band.mean() + peak_thr_k * band.std())\n",
        "    coords = peak_local_max(\n",
        "        band,\n",
        "        min_distance=peak_min_dist,\n",
        "        threshold_abs=thr,\n",
        "        exclude_border=False,\n",
        "    ).astype(np.int32)\n",
        "\n",
        "    labels = None\n",
        "    if use_watershed and len(coords) > 0:\n",
        "        markers = np.zeros_like(img, dtype=np.int32)\n",
        "        for i, (r, c) in enumerate(coords, 1):\n",
        "            markers[r, c] = i\n",
        "        labels = watershed(-band, markers, mask=(band > band.mean()))\n",
        "\n",
        "    return {\n",
        "        \"raw\": img,\n",
        "        \"norm01\": normalize01(img),\n",
        "        \"denoise\": den,\n",
        "        \"band\": band,\n",
        "        \"coords\": coords,\n",
        "        \"labels\": labels,\n",
        "        \"thr\": thr,\n",
        "    }\n",
        "\n",
        "def estimate_lattice_fft_robust(img, topk=24, exclude=3, min_dist=4, collinear_thresh=0.93):\n",
        "    fft = np.abs(np.fft.fftshift(np.fft.fft2(img)))\n",
        "    cy, cx = np.array(fft.shape) // 2\n",
        "\n",
        "    rr, cc = np.ogrid[:fft.shape[0], :fft.shape[1]]\n",
        "    fft[(rr - cy) ** 2 + (cc - cx) ** 2 <= exclude ** 2] = 0\n",
        "\n",
        "    rec_peaks = peak_local_max(fft, min_distance=min_dist, threshold_abs=0, exclude_border=False)\n",
        "    if len(rec_peaks) < 6:\n",
        "        raise RuntimeError(\"Too few FFT peaks found\")\n",
        "\n",
        "    vals = fft[rec_peaks[:, 0], rec_peaks[:, 1]]\n",
        "    order = np.argsort(vals)[::-1][:topk]\n",
        "    rec_peaks = rec_peaks[order]\n",
        "\n",
        "    cand = []\n",
        "    for p in rec_peaks:\n",
        "        delta = (p - np.array([cy, cx], dtype=np.float32))\n",
        "        if np.allclose(delta, 0):\n",
        "            continue\n",
        "        freq_vec = delta / np.array(img.shape, dtype=np.float32)\n",
        "        norm = np.linalg.norm(freq_vec)\n",
        "        if norm < 1e-6:\n",
        "            continue\n",
        "        real_vec = (freq_vec / norm) * (1.0 / norm)\n",
        "        cand.append(real_vec.astype(np.float32))\n",
        "\n",
        "    cand = np.stack(cand, axis=0)\n",
        "\n",
        "    best = None\n",
        "    best_score = -np.inf\n",
        "    for i in range(len(cand)):\n",
        "        for j in range(i+1, len(cand)):\n",
        "            v1, v2 = cand[i], cand[j]\n",
        "            n1, n2 = np.linalg.norm(v1), np.linalg.norm(v2)\n",
        "            if n1 < 1e-3 or n2 < 1e-3:\n",
        "                continue\n",
        "            cosang = np.abs(np.dot(v1, v2) / (n1*n2 + 1e-12))\n",
        "            if cosang > collinear_thresh:\n",
        "                continue\n",
        "            score = (1.0 - cosang) - 0.25*np.abs(np.log((n1+1e-6)/(n2+1e-6)))\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best = (v1, v2)\n",
        "\n",
        "    if best is None:\n",
        "        raise RuntimeError(\"FFT basis selection failed\")\n",
        "    return best\n",
        "\n",
        "def lattice_spacing(v1, v2):\n",
        "    return float(0.5 * (np.linalg.norm(v1) + np.linalg.norm(v2)))\n",
        "\n",
        "def generate_lattice_sites(img_shape, origin, v1, v2):\n",
        "    h, w = img_shape\n",
        "    A = np.stack([v1, v2], axis=1).astype(np.float32)\n",
        "    Ai = np.linalg.pinv(A)\n",
        "\n",
        "    corners = np.array([[0,0],[0,w],[h,0],[h,w]], dtype=np.float32) - origin\n",
        "    uv = corners @ Ai.T\n",
        "\n",
        "    umin, vmin = np.floor(uv.min(axis=0) - 2).astype(int)\n",
        "    umax, vmax = np.ceil(uv.max(axis=0) + 2).astype(int)\n",
        "\n",
        "    pts = []\n",
        "    for u in range(umin, umax+1):\n",
        "        for v in range(vmin, vmax+1):\n",
        "            p = origin + u*v1 + v*v2\n",
        "            if 0 <= p[0] < h and 0 <= p[1] < w:\n",
        "                pts.append(p)\n",
        "    return np.array(pts, dtype=np.float32)\n",
        "\n",
        "def refine_origin_unitcell(peaks, origin, v1, v2, img_shape, tol, grid=21):\n",
        "    H, W = img_shape\n",
        "    peaks = peaks.astype(np.float32)\n",
        "    if len(peaks) < 6:\n",
        "        return origin.astype(np.float32), 0\n",
        "\n",
        "    treeP = cKDTree(peaks)\n",
        "    A = np.stack([v1, v2], axis=1).astype(np.float32)\n",
        "    Ai = np.linalg.pinv(A)\n",
        "    corners = np.array([[0,0],[0,W],[H,0],[H,W]], dtype=np.float32)\n",
        "\n",
        "    def expected_for_origin(o):\n",
        "        uv = (corners - o) @ Ai.T\n",
        "        umin, vmin = np.floor(uv.min(axis=0) - 2).astype(int)\n",
        "        umax, vmax = np.ceil(uv.max(axis=0) + 2).astype(int)\n",
        "        pts = []\n",
        "        for u in range(umin, umax+1):\n",
        "            for v in range(vmin, vmax+1):\n",
        "                p = o + u*v1 + v*v2\n",
        "                if 0 <= p[0] < H and 0 <= p[1] < W:\n",
        "                    pts.append(p)\n",
        "        return np.array(pts, dtype=np.float32)\n",
        "\n",
        "    best_score, best_origin = -1, origin.astype(np.float32)\n",
        "    aa = np.linspace(0.0, 1.0, grid, endpoint=False)\n",
        "    bb = np.linspace(0.0, 1.0, grid, endpoint=False)\n",
        "\n",
        "    for a in aa:\n",
        "        for b in bb:\n",
        "            o = origin + a*v1 + b*v2\n",
        "            exp_sites = expected_for_origin(o)\n",
        "            if len(exp_sites) == 0:\n",
        "                continue\n",
        "            d, _ = treeP.query(exp_sites, k=1)\n",
        "            score = int(np.sum(d <= tol))\n",
        "            if score > best_score:\n",
        "                best_score, best_origin = score, o\n",
        "\n",
        "    return best_origin, best_score\n",
        "\n",
        "def assign_and_classify(detected, expected, r_assign):\n",
        "    detected = detected.astype(np.float32)\n",
        "    expected = expected.astype(np.float32)\n",
        "\n",
        "    if len(expected) == 0:\n",
        "        return (np.array([], dtype=np.uint8),\n",
        "                np.array([], dtype=np.int32),\n",
        "                np.zeros((0,2), dtype=np.int32),\n",
        "                np.zeros((0,2), dtype=np.int32))\n",
        "\n",
        "    treeE = cKDTree(expected)\n",
        "    d_dist, d_nn = treeE.query(detected, k=1)\n",
        "    close = d_dist <= r_assign\n",
        "\n",
        "    exp_to_det = -np.ones(len(expected), dtype=np.int32)\n",
        "    by_site = {}\n",
        "    for j in range(len(detected)):\n",
        "        if close[j]:\n",
        "            by_site.setdefault(int(d_nn[j]), []).append(j)\n",
        "\n",
        "    extra_atom = []\n",
        "    for sid, js in by_site.items():\n",
        "        js = np.array(js, dtype=int)\n",
        "        j0 = js[np.argmin(d_dist[js])]\n",
        "        exp_to_det[sid] = j0\n",
        "        for jj in js:\n",
        "            if jj != j0:\n",
        "                extra_atom.append(detected[jj])\n",
        "\n",
        "    site_class = np.zeros(len(expected), dtype=np.uint8)\n",
        "    site_class[exp_to_det < 0] = 1  # missing\n",
        "\n",
        "    extra_atom = np.array(extra_atom, dtype=np.int32) if len(extra_atom) else np.zeros((0,2), dtype=np.int32)\n",
        "    extra_interstitial = detected[~close].astype(np.int32) if len(detected) else np.zeros((0,2), dtype=np.int32)\n",
        "\n",
        "    return site_class, exp_to_det, extra_atom, extra_interstitial\n",
        "\n",
        "def semantic_mask(img_shape, expected, site_class, extra_atom, extra_interstitial, watershed_labels=None, stamp_radius=3):\n",
        "    H, W = img_shape\n",
        "    rr, cc = np.mgrid[0:H, 0:W]\n",
        "    pix = np.stack([rr.ravel(), cc.ravel()], axis=1).astype(np.float32)\n",
        "\n",
        "    treeE = cKDTree(expected.astype(np.float32))\n",
        "    _, nn = treeE.query(pix, k=1)\n",
        "    nn = nn.reshape(H, W)\n",
        "\n",
        "    seg = np.zeros((H, W), dtype=np.uint8)\n",
        "    seg[site_class[nn] == 1] = NAME2ID[\"missing\"]\n",
        "\n",
        "    if watershed_labels is not None:\n",
        "        seg_ws = np.zeros_like(seg)\n",
        "        nreg = int(watershed_labels.max())\n",
        "        for rid in range(1, nreg+1):\n",
        "            m = (watershed_labels == rid)\n",
        "            if not np.any(m):\n",
        "                continue\n",
        "            ys, xs = np.where(m)\n",
        "            cy, cx = float(ys.mean()), float(xs.mean())\n",
        "            _, sid = treeE.query([[cy, cx]], k=1)\n",
        "            sid = int(sid[0])\n",
        "            seg_ws[m] = NAME2ID[\"missing\"] if site_class[sid] == 1 else NAME2ID[\"bulk\"]\n",
        "        seg = seg_ws\n",
        "\n",
        "    rad = int(max(2, stamp_radius))\n",
        "\n",
        "    def stamp(points, cls_id):\n",
        "        if len(points) == 0:\n",
        "            return\n",
        "        for (r, c) in points:\n",
        "            r0, r1 = max(0, r-rad), min(H, r+rad+1)\n",
        "            c0, c1 = max(0, c-rad), min(W, c+rad+1)\n",
        "            seg[r0:r1, c0:c1] = np.maximum(seg[r0:r1, c0:c1], cls_id)\n",
        "\n",
        "    stamp(extra_atom, NAME2ID[\"extra_atom\"])\n",
        "    stamp(extra_interstitial, NAME2ID[\"extra_interstitial\"])\n",
        "    return seg\n",
        "\n",
        "def overlay_rgba(gray01, seg):\n",
        "    rgba = np.dstack([gray01, gray01, gray01, np.ones_like(gray01)])\n",
        "    out = rgba.copy()\n",
        "    for name, col in COLOR.items():\n",
        "        cls = NAME2ID[name]\n",
        "        a = float(col[3])\n",
        "        if a <= 0:\n",
        "            continue\n",
        "        m = (seg == cls)\n",
        "        out[m] = (1-a)*out[m] + a*col\n",
        "    return out\n",
        "\n",
        "def save_debug_png(res, expected, site_class, exp_to_det, seg, out_path_prefix):\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
        "\n",
        "    ax[0].imshow(res[\"band\"], cmap=\"magma\")\n",
        "    ax[0].set_title(f\"DoG bandpass (thr={res['thr']:.3f})\")\n",
        "    ax[0].axis(\"off\")\n",
        "\n",
        "    ax[1].imshow(overlay_rgba(res[\"norm01\"], seg))\n",
        "    ax[1].set_title(\"semantic overlay\")\n",
        "    ax[1].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    fig.savefig(out_path_prefix + \"_dog_overlay.png\", dpi=160)\n",
        "    plt.close(fig)\n",
        "\n",
        "# =========================\n",
        "# MAIN\n",
        "# =========================\n",
        "with h5py.File(H5_IN, \"r\") as fin:\n",
        "    imgs = fin[\"images\"]\n",
        "    labels = fin[\"labels\"][:] if (\"labels\" in fin and USE_LABELS_FROM_H5) else None\n",
        "    label_names = None\n",
        "    if USE_LABELS_FROM_H5 and \"meta/label_names\" in fin:\n",
        "        label_names = [x.decode() for x in fin[\"meta/label_names\"][:]]\n",
        "\n",
        "# output H5 with only 4 masks\n",
        "h5_out = os.path.join(OUT_DIR, \"sto_4case_masks.h5\")\n",
        "with h5py.File(H5_IN, \"r\") as fin, h5py.File(h5_out, \"w\") as fout:\n",
        "    g = fout.create_group(\"cases\")\n",
        "    for idx in CASE_IDXS:\n",
        "        img = fin[\"images\"][idx]\n",
        "\n",
        "        # decide allow_interstitial per-case from H5 label if possible\n",
        "        allow_interstitial = False\n",
        "        case_label_str = \"unknown\"\n",
        "        if labels is not None and label_names is not None:\n",
        "            case_label_str = label_names[int(labels[idx])]\n",
        "            allow_interstitial = (\"IExtra_3\" in case_label_str)\n",
        "        else:\n",
        "            case_label_str = image_label\n",
        "            allow_interstitial = (\"IExtra_3\" in case_label_str)\n",
        "\n",
        "        res = locate_atoms(img, denoise_weight, dog_sigma1, dog_sigma2, peak_min_dist, peak_thr_k, use_watershed)\n",
        "\n",
        "        v1, v2 = estimate_lattice_fft_robust(\n",
        "            res[\"denoise\"], topk=fft_topk, exclude=fft_peak_exclude, min_dist=fft_min_dist, collinear_thresh=fft_collinear_thresh\n",
        "        )\n",
        "        lat = lattice_spacing(v1, v2)\n",
        "\n",
        "        # robust radius\n",
        "        r_assign = ASSIGN_MULT * lat if USE_AUTO_ASSIGN else assign_radius_fallback\n",
        "        r_assign = float(max(3.0, r_assign))\n",
        "\n",
        "        if len(res[\"coords\"]) > 0:\n",
        "            origin0 = res[\"coords\"][np.argmin(np.sum((res[\"coords\"] - np.median(res[\"coords\"], axis=0))**2, axis=1))].astype(np.float32)\n",
        "        else:\n",
        "            origin0 = (np.array(img.shape, dtype=np.float32) / 2.0)\n",
        "\n",
        "        origin, _ = refine_origin_unitcell(\n",
        "            peaks=res[\"coords\"], origin=origin0, v1=v1, v2=v2, img_shape=img.shape, tol=r_assign, grid=21\n",
        "        )\n",
        "\n",
        "        expected = generate_lattice_sites(img.shape, origin, v1, v2)\n",
        "        site_class, exp_to_det, extra_atom, extra_interstitial = assign_and_classify(res[\"coords\"], expected, r_assign=r_assign)\n",
        "\n",
        "        if not allow_interstitial:\n",
        "            extra_interstitial = np.zeros((0,2), dtype=np.int32)\n",
        "\n",
        "        seg = semantic_mask(\n",
        "            img.shape, expected, site_class, extra_atom, extra_interstitial,\n",
        "            watershed_labels=res[\"labels\"] if use_watershed else None,\n",
        "            stamp_radius=max(2, int(0.18 * lat))\n",
        "        )\n",
        "\n",
        "        # save to h5\n",
        "        cg = g.create_group(str(idx))\n",
        "        cg.create_dataset(\"image\", data=img, compression=\"gzip\")\n",
        "        cg.create_dataset(\"mask\", data=seg.astype(np.uint8), compression=\"gzip\")\n",
        "        cg.create_dataset(\"coords_detected\", data=res[\"coords\"].astype(np.int32), compression=\"gzip\")\n",
        "        cg.create_dataset(\"sites_expected\", data=expected.astype(np.float32), compression=\"gzip\")\n",
        "        cg.attrs[\"label_str\"] = case_label_str\n",
        "        cg.attrs[\"allow_interstitial\"] = bool(allow_interstitial)\n",
        "        cg.attrs[\"lat_spacing_px\"] = float(lat)\n",
        "        cg.attrs[\"r_assign_px\"] = float(r_assign)\n",
        "        cg.attrs[\"peak_thr_k\"] = float(peak_thr_k)\n",
        "\n",
        "        # save debug PNG\n",
        "        prefix = os.path.join(OUT_DIR, f\"idx{idx}_label{case_label_str.replace('/','_')}\")\n",
        "        save_debug_png(res, expected, site_class, exp_to_det, seg, prefix)\n",
        "\n",
        "        print(f\"[idx={idx}] label={case_label_str} lat={lat:.2f}px r_assign={r_assign:.2f}px \"\n",
        "              f\"peaks={len(res['coords'])} expected={len(expected)} \"\n",
        "              f\"missing_sites={int(np.sum(site_class==1))} extras={len(extra_atom)} inter={len(extra_interstitial)}\")\n",
        "\n",
        "print(\"Saved:\", h5_out)\n",
        "print(\"PNG debug outputs in:\", OUT_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "D  image_keys  shape=(764,) dtype=|S10\n",
            "G  images\n",
            "D  images/bulk_0  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_1  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_10  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_100  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_101  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_102  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_103  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_104  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_105  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_106  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_107  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_108  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_109  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_11  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_110  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_111  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_112  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_113  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_114  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_115  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_116  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_117  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_118  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_119  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_12  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_120  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_121  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_122  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_123  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_124  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_125  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_126  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_127  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_128  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_129  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_13  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_130  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_131  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_132  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_133  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_134  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_135  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_136  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_137  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_138  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_139  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_14  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_140  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_141  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_142  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_143  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_144  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_145  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_146  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_147  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_148  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_149  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_15  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_150  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_151  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_152  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_153  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_154  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_155  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_156  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_157  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_158  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_159  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_16  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_160  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_161  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_162  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_163  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_164  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_165  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_166  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_167  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_168  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_169  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_17  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_170  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_171  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_172  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_173  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_174  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_175  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_176  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_177  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_178  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_179  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_18  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_180  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_181  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_182  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_183  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_184  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_185  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_186  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_187  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_188  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_189  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_19  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_190  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_191  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_192  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_193  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_194  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_195  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_196  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_197  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_198  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_199  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_2  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_20  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_200  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_201  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_202  shape=(64, 64) dtype=float64\n",
            "D  images/bulk_203  shape=(64, 64) dtype=float64\n",
            "... (647 more)\n"
          ]
        }
      ],
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "def _is_dataset(obj):\n",
        "    return isinstance(obj, h5py.Dataset)\n",
        "\n",
        "def _find_first_dataset_by_name(h5f, name_candidates):\n",
        "    \"\"\"\n",
        "    Search entire file for dataset whose basename matches any candidate.\n",
        "    Returns dataset path or None.\n",
        "    \"\"\"\n",
        "    found = []\n",
        "\n",
        "    def visitor(name, obj):\n",
        "        if _is_dataset(obj):\n",
        "            base = name.split(\"/\")[-1]\n",
        "            if base in name_candidates:\n",
        "                found.append(name)\n",
        "\n",
        "    h5f.visititems(visitor)\n",
        "    return found[0] if found else None\n",
        "\n",
        "def get_images_dataset(h5f):\n",
        "    # common cases: \"images\" dataset or nested\n",
        "    if \"images\" in h5f and _is_dataset(h5f[\"images\"]):\n",
        "        return h5f[\"images\"]\n",
        "    p = _find_first_dataset_by_name(h5f, {\"images\", \"image\"})\n",
        "    if p is None:\n",
        "        raise KeyError(\"Could not find images dataset in H5 (looked for 'images'/'image').\")\n",
        "    return h5f[p]\n",
        "\n",
        "def get_labels_array(h5f, allow_missing=True):\n",
        "    \"\"\"\n",
        "    Returns labels as numpy array or None if missing and allow_missing=True.\n",
        "    Handles cases where 'labels' is a group.\n",
        "    \"\"\"\n",
        "    # direct dataset\n",
        "    if \"labels\" in h5f and _is_dataset(h5f[\"labels\"]):\n",
        "        return h5f[\"labels\"][:]\n",
        "\n",
        "    # if 'labels' is a group, try inside it\n",
        "    if \"labels\" in h5f and isinstance(h5f[\"labels\"], h5py.Group):\n",
        "        grp = h5f[\"labels\"]\n",
        "        for k in [\"labels\", \"y\", \"target\", \"class\", \"classes\"]:\n",
        "            if k in grp and _is_dataset(grp[k]):\n",
        "                return grp[k][:]\n",
        "\n",
        "    # global search\n",
        "    p = _find_first_dataset_by_name(h5f, {\"labels\", \"y\", \"target\"})\n",
        "    if p is not None:\n",
        "        return h5f[p][:]\n",
        "\n",
        "    if allow_missing:\n",
        "        return None\n",
        "    raise KeyError(\"Could not find labels dataset in H5.\")\n",
        "\n",
        "def get_label_names(h5f):\n",
        "    \"\"\"\n",
        "    Returns list[str] or None.\n",
        "    \"\"\"\n",
        "    # common path\n",
        "    if \"meta/label_names\" in h5f and _is_dataset(h5f[\"meta/label_names\"]):\n",
        "        return [x.decode() if isinstance(x, (bytes, np.bytes_)) else str(x) for x in h5f[\"meta/label_names\"][:]]\n",
        "\n",
        "    # search\n",
        "    p = _find_first_dataset_by_name(h5f, {\"label_names\", \"names\", \"class_names\"})\n",
        "    if p is None:\n",
        "        return None\n",
        "    arr = h5f[p][:]\n",
        "    return [x.decode() if isinstance(x, (bytes, np.bytes_)) else str(x) for x in arr]\n",
        "\n",
        "def debug_print_h5_tree(h5_path, max_lines=80):\n",
        "    \"\"\"\n",
        "    Prints a compact tree so you can see what 'labels' actually is.\n",
        "    \"\"\"\n",
        "    lines = []\n",
        "    with h5py.File(h5_path, \"r\") as f:\n",
        "        def visitor(name, obj):\n",
        "            if isinstance(obj, h5py.Group):\n",
        "                lines.append(f\"G  {name}\")\n",
        "            else:\n",
        "                lines.append(f\"D  {name}  shape={obj.shape} dtype={obj.dtype}\")\n",
        "        f.visititems(visitor)\n",
        "\n",
        "    print(\"\\n\".join(lines[:max_lines]))\n",
        "    if len(lines) > max_lines:\n",
        "        print(f\"... ({len(lines)-max_lines} more)\")\n",
        "\n",
        "debug_print_h5_tree(\"sto_dataset.h5\", max_lines=120)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Accessing a group is done with bytes or str, not <class 'slice'>",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[42], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(h5_in, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fin, h5py\u001b[38;5;241m.\u001b[39mFile(h5_mask_out, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fout:\n\u001b[1;32m      7\u001b[0m     imgs \u001b[38;5;241m=\u001b[39m fin[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 8\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[43mfin\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m fin \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(imgs)\n\u001b[1;32m     10\u001b[0m     H, W \u001b[38;5;241m=\u001b[39m imgs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\n",
            "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m~/miniforge3/envs/dinov2-extras/lib/python3.10/site-packages/h5py/_hl/group.py:369\u001b[0m, in \u001b[0;36mGroup.__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    367\u001b[0m     oid \u001b[38;5;241m=\u001b[39m h5o\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_e(name), lapl\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lapl)\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 369\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccessing a group is done with bytes or str, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    370\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(name)))\n\u001b[1;32m    372\u001b[0m otype \u001b[38;5;241m=\u001b[39m h5i\u001b[38;5;241m.\u001b[39mget_type(oid)\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m otype \u001b[38;5;241m==\u001b[39m h5i\u001b[38;5;241m.\u001b[39mGROUP:\n",
            "\u001b[0;31mTypeError\u001b[0m: Accessing a group is done with bytes or str, not <class 'slice'>"
          ]
        }
      ],
      "source": [
        "import h5py, numpy as np\n",
        "\n",
        "h5_in = \"sto_dataset.h5\"\n",
        "h5_mask_out = \"sto_masks_level0.h5\"\n",
        "\n",
        "with h5py.File(h5_in, \"r\") as fin, h5py.File(h5_mask_out, \"w\") as fout:\n",
        "    imgs = fin[\"images\"]\n",
        "    labels = fin[\"labels\"][:] if \"labels\" in fin else None\n",
        "    n = len(imgs)\n",
        "    H, W = imgs[0].shape\n",
        "\n",
        "    seg_ds = fout.create_dataset(\"seg\", shape=(n, H, W), dtype=\"uint8\", compression=\"gzip\")\n",
        "    fout.create_dataset(\"labels\", data=labels) if labels is not None else None\n",
        "\n",
        "    # carry metadata if available\n",
        "    for k in [\"meta/paths\", \"meta/label_names\"]:\n",
        "        if k in fin:\n",
        "            fout.create_dataset(k, data=fin[k][:])\n",
        "\n",
        "    for i in range(n):\n",
        "        img = imgs[i]\n",
        "        # ---- run your pipeline here ----\n",
        "        res = locate_atoms(img)\n",
        "        v1, v2 = estimate_lattice_fft_robust(\n",
        "            res[\"denoise\"],\n",
        "            topk=fft_topk,\n",
        "            exclude=fft_peak_exclude,\n",
        "            min_dist=fft_min_dist,\n",
        "            collinear_thresh=fft_collinear_thresh\n",
        "        )\n",
        "        origin0 = res[\"coords\"][np.argmin(np.sum((res[\"coords\"] - np.median(res[\"coords\"], axis=0))**2, axis=1))].astype(np.float32) if len(res[\"coords\"]) else (np.array(img.shape, dtype=np.float32)/2)\n",
        "        origin, _ = refine_origin_unitcell(res[\"coords\"], origin0, v1, v2, img.shape, tol=assign_radius, grid=31)\n",
        "        expected = generate_lattice_sites(img.shape, origin, v1, v2)\n",
        "        site_class, exp_to_det, extra_atom, extra_interstitial = assign_and_classify(res[\"coords\"], expected, r_assign=assign_radius)\n",
        "\n",
        "        # interstitial gating using true label name (if you have it)\n",
        "        allow_interstitial = False\n",
        "        if labels is not None and \"meta/label_names\" in fin:\n",
        "            names = [x.decode() for x in fin[\"meta/label_names\"][:]]\n",
        "            allow_interstitial = (\"IExtra_3\" in names[int(labels[i])])\n",
        "        if not allow_interstitial:\n",
        "            extra_interstitial = np.zeros((0,2), dtype=np.int32)\n",
        "\n",
        "        seg = semantic_mask(\n",
        "            img.shape, expected, site_class, extra_atom, extra_interstitial,\n",
        "            watershed_labels=res[\"labels\"] if use_watershed else None,\n",
        "            stamp_radius=assign_radius/3\n",
        "        )\n",
        "        seg_ds[i] = seg\n",
        "\n",
        "print(\"Saved masks to\", h5_mask_out)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Mask free embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Jupyter cell: MASK-FREE DINOv2 embeddings using top-k patch pooling (no ROI/masks)\n",
        "import h5py, numpy as np, torch\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "\n",
        "DINO_MODEL = \"dinov2_vitb14\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "PATCH_SIZE = 224\n",
        "batch_size = 128\n",
        "\n",
        "h5_in  = \"sto_dataset.h5\"\n",
        "h5_out = \"sto_embeddings_nomask.h5\"\n",
        "\n",
        "IMNET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMNET_STD  = (0.229, 0.224, 0.225)\n",
        "\n",
        "# ---- load model ----\n",
        "model = torch.hub.load(\"facebookresearch/dinov2\", DINO_MODEL).to(DEVICE).eval()\n",
        "\n",
        "def normalize01(img2d):\n",
        "    img2d = img2d.astype(np.float32)\n",
        "    p1, p99 = np.percentile(img2d, (1, 99))\n",
        "    return np.clip((img2d - p1) / (p99 - p1 + 1e-6), 0, 1)\n",
        "\n",
        "def pil_to_tensor_no_numpy(pil_img: Image.Image) -> torch.Tensor:\n",
        "    pil_img = pil_img.convert(\"RGB\")\n",
        "    w, h = pil_img.size\n",
        "    b = pil_img.tobytes()\n",
        "    storage = torch.ByteStorage.from_buffer(b)\n",
        "    x = torch.ByteTensor(storage).view(h, w, 3).permute(2, 0, 1).contiguous()\n",
        "    return x.float().div_(255.0)\n",
        "\n",
        "def preprocess_gray2d_to_dino(img2d, out_size=224):\n",
        "    # full image -> uint8 RGB\n",
        "    g01 = normalize01(img2d)\n",
        "    u8 = (g01 * 255.0 + 0.5).astype(np.uint8)\n",
        "    rgb = np.repeat(u8[..., None], 3, axis=-1)  # HxWx3\n",
        "\n",
        "    h, w, _ = rgb.shape\n",
        "    pil = Image.frombytes(\"RGB\", (w, h), rgb.tobytes())\n",
        "    x = pil_to_tensor_no_numpy(pil).unsqueeze(0)  # (1,3,H,W)\n",
        "\n",
        "    x = F.interpolate(x, size=(out_size, out_size), mode=\"bicubic\", align_corners=False)\n",
        "\n",
        "    mean = torch.tensor(IMNET_MEAN, dtype=x.dtype).view(1, 3, 1, 1)\n",
        "    std  = torch.tensor(IMNET_STD,  dtype=x.dtype).view(1, 3, 1, 1)\n",
        "    x = (x - mean) / std\n",
        "    return x\n",
        "\n",
        "@torch.inference_mode()\n",
        "def embed_batch_topk_torch(img2d_list, topk=32):\n",
        "    xs = [preprocess_gray2d_to_dino(im, out_size=PATCH_SIZE) for im in img2d_list]\n",
        "    x = torch.cat(xs, dim=0).to(DEVICE, non_blocking=True)  # (B,3,224,224)\n",
        "\n",
        "    feats = model.forward_features(x)[\"x_norm_patchtokens\"]  # (B, N, D)\n",
        "    score = torch.linalg.norm(feats, dim=-1)                # (B, N)\n",
        "    k = min(topk, feats.shape[1])\n",
        "    idx = torch.topk(score, k=k, dim=1, largest=True).indices  # (B, k)\n",
        "\n",
        "    B, N, D = feats.shape\n",
        "    idx_exp = idx.unsqueeze(-1).expand(B, k, D)\n",
        "    top_tokens = torch.gather(feats, dim=1, index=idx_exp)  # (B,k,D)\n",
        "    emb = top_tokens.mean(dim=1)                            # (B,D)\n",
        "\n",
        "    return emb.detach().to(\"cpu\", non_blocking=False).float().contiguous()\n",
        "\n",
        "\n",
        "# ---- main ----\n",
        "with h5py.File(h5_in, \"r\") as fin, h5py.File(h5_out, \"w\") as fout:\n",
        "    imgs = fin[\"images\"]\n",
        "    labels = fin[\"labels\"][:] if \"labels\" in fin else None\n",
        "    n = len(imgs)\n",
        "\n",
        "    emb_dim = 768  # vitb14\n",
        "    emb_ds = fout.create_dataset(\"embeddings\", shape=(n, emb_dim), dtype=\"float32\", compression=\"gzip\")\n",
        "    if labels is not None:\n",
        "        fout.create_dataset(\"labels\", data=labels)\n",
        "\n",
        "    for k in [\"meta/paths\", \"meta/label_names\"]:\n",
        "        if k in fin:\n",
        "            fout.create_dataset(k, data=fin[k][:])\n",
        "\n",
        "    buf, idxs = [], []\n",
        "    for i in range(n):\n",
        "        buf.append(imgs[i])\n",
        "        idxs.append(i)\n",
        "        if len(buf) == batch_size or i == n - 1:\n",
        "            emb_t = embed_batch_topk_torch(buf, topk=32)        # torch CPU tensor (B,D)\n",
        "            emb_np = np.asarray(emb_t.tolist(), dtype=np.float32)  # slow-ish but works without torch<->numpy bridge\n",
        "            emb_ds[idxs[0]:idxs[0] + len(buf)] = emb_np\n",
        "            buf, idxs = [], []\n",
        "\n",
        "print(\"Saved mask-free embeddings to\", h5_out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /home/gowthamnh/.cache/torch/hub/facebookresearch_dinov2_main\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "\"Could not find images dataset in H5 (looked for 'images'/'image').\"",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[40], line 65\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# ---- main ----\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(h5_in, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fin, h5py\u001b[38;5;241m.\u001b[39mFile(h5_out, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fout:\n\u001b[0;32m---> 65\u001b[0m     imgs \u001b[38;5;241m=\u001b[39m \u001b[43mget_images_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     labels \u001b[38;5;241m=\u001b[39m get_labels_array(fin, allow_missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     67\u001b[0m     label_names \u001b[38;5;241m=\u001b[39m get_label_names(fin)\n",
            "Cell \u001b[0;32mIn[39], line 29\u001b[0m, in \u001b[0;36mget_images_dataset\u001b[0;34m(h5f)\u001b[0m\n\u001b[1;32m     27\u001b[0m p \u001b[38;5;241m=\u001b[39m _find_first_dataset_by_name(h5f, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find images dataset in H5 (looked for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m h5f[p]\n",
            "\u001b[0;31mKeyError\u001b[0m: \"Could not find images dataset in H5 (looked for 'images'/'image').\""
          ]
        }
      ],
      "source": [
        "# Jupyter cell: MASK-FREE DINOv2 embeddings using top-k patch pooling (no ROI/masks)\n",
        "import h5py, numpy as np, torch\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "DINO_MODEL = \"dinov2_vitb14\"\n",
        "PATCH_SIZE = 224\n",
        "batch_size = 128\n",
        "\n",
        "h5_in  = \"sto_dataset.h5\"\n",
        "h5_out = \"sto_embeddings_nomask.h5\"\n",
        "\n",
        "IMNET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMNET_STD  = (0.229, 0.224, 0.225)\n",
        "\n",
        "# ---- load model ----\n",
        "model = torch.hub.load(\"facebookresearch/dinov2\", DINO_MODEL).to(DEVICE).eval()\n",
        "\n",
        "def normalize01(img2d):\n",
        "    img2d = img2d.astype(np.float32)\n",
        "    p1, p99 = np.percentile(img2d, (1, 99))\n",
        "    return np.clip((img2d - p1) / (p99 - p1 + 1e-6), 0, 1)\n",
        "\n",
        "def pil_to_tensor_no_numpy(pil_img: Image.Image) -> torch.Tensor:\n",
        "    pil_img = pil_img.convert(\"RGB\")\n",
        "    w, h = pil_img.size\n",
        "    b = pil_img.tobytes()\n",
        "    storage = torch.ByteStorage.from_buffer(b)\n",
        "    x = torch.ByteTensor(storage).view(h, w, 3).permute(2, 0, 1).contiguous()\n",
        "    return x.float().div_(255.0)\n",
        "\n",
        "def preprocess_gray2d_to_dino(img2d, out_size=224):\n",
        "    g01 = normalize01(img2d)\n",
        "    u8 = (g01 * 255.0 + 0.5).astype(np.uint8)\n",
        "    rgb = np.repeat(u8[..., None], 3, axis=-1)  # HxWx3\n",
        "\n",
        "    h, w, _ = rgb.shape\n",
        "    pil = Image.frombytes(\"RGB\", (w, h), rgb.tobytes())\n",
        "    x = pil_to_tensor_no_numpy(pil).unsqueeze(0)  # (1,3,H,W)\n",
        "    x = F.interpolate(x, size=(out_size, out_size), mode=\"bicubic\", align_corners=False)\n",
        "\n",
        "    mean = torch.tensor(IMNET_MEAN, dtype=x.dtype).view(1, 3, 1, 1)\n",
        "    std  = torch.tensor(IMNET_STD,  dtype=x.dtype).view(1, 3, 1, 1)\n",
        "    return (x - mean) / std\n",
        "\n",
        "@torch.inference_mode()\n",
        "def embed_batch_topk_torch(img2d_list, topk=32):\n",
        "    xs = [preprocess_gray2d_to_dino(im, out_size=PATCH_SIZE) for im in img2d_list]\n",
        "    x = torch.cat(xs, dim=0).to(DEVICE, non_blocking=True)  # (B,3,224,224)\n",
        "\n",
        "    feats = model.forward_features(x)[\"x_norm_patchtokens\"]  # (B, N, D)\n",
        "    score = torch.linalg.norm(feats, dim=-1)                # (B, N)\n",
        "    k = min(topk, feats.shape[1])\n",
        "    idx = torch.topk(score, k=k, dim=1, largest=True).indices  # (B, k)\n",
        "\n",
        "    B, N, D = feats.shape\n",
        "    idx_exp = idx.unsqueeze(-1).expand(B, k, D)\n",
        "    top_tokens = torch.gather(feats, dim=1, index=idx_exp)  # (B,k,D)\n",
        "    emb = top_tokens.mean(dim=1)                            # (B,D)\n",
        "    return emb.detach().to(\"cpu\", non_blocking=False).float().contiguous()\n",
        "\n",
        "# ---- main ----\n",
        "with h5py.File(h5_in, \"r\") as fin, h5py.File(h5_out, \"w\") as fout:\n",
        "    imgs = get_images_dataset(fin)\n",
        "    labels = get_labels_array(fin, allow_missing=True)\n",
        "    label_names = get_label_names(fin)\n",
        "\n",
        "    n = len(imgs)\n",
        "    emb_dim = 768\n",
        "    emb_ds = fout.create_dataset(\"embeddings\", shape=(n, emb_dim), dtype=\"float32\", compression=\"gzip\")\n",
        "\n",
        "    if labels is not None:\n",
        "        fout.create_dataset(\"labels\", data=labels)\n",
        "    if label_names is not None:\n",
        "        fout.create_dataset(\"meta/label_names\", data=np.array(label_names, dtype=\"S\"))\n",
        "\n",
        "    # copy other helpful metadata if present\n",
        "    for k in [\"meta/paths\", \"paths\"]:\n",
        "        if k in fin and isinstance(fin[k], h5py.Dataset):\n",
        "            fout.create_dataset(\"meta/paths\", data=fin[k][:])\n",
        "\n",
        "    buf, idxs = [], []\n",
        "    for i in range(n):\n",
        "        buf.append(imgs[i])\n",
        "        idxs.append(i)\n",
        "        if len(buf) == batch_size or i == n - 1:\n",
        "            emb_t = embed_batch_topk_torch(buf, topk=32)  # torch CPU (B,D)\n",
        "            emb_np = np.asarray(emb_t.tolist(), dtype=np.float32)  # bridge-safe\n",
        "            emb_ds[idxs[0]:idxs[0] + len(buf)] = emb_np\n",
        "            buf, idxs = [], []\n",
        "\n",
        "print(\"Saved mask-free embeddings to\", h5_out)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Self supervised embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Jupyter cell: ROI-based DINOv2 embeddings WITHOUT torchvision ToTensor / torch.from_numpy\n",
        "# Works around: RuntimeError: Numpy is not available\n",
        "\n",
        "import h5py, numpy as np, torch\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "\n",
        "# ----------------------------\n",
        "# Config\n",
        "# ----------------------------\n",
        "DINO_MODEL = \"dinov2_vitb14\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "PATCH_SIZE = 224\n",
        "\n",
        "h5_in = \"sto_dataset.h5\"\n",
        "h5_masks = \"sto_masks_level0.h5\"      # produced by your Level-0 pipeline\n",
        "h5_out = \"sto_embeddings_roi.h5\"\n",
        "batch_size = 128\n",
        "\n",
        "# ROI params\n",
        "DEFECT_CLASSES = (1, 2, 3)            # missing, extra_atom, extra_interstitial\n",
        "ROI_MARGIN = 20\n",
        "MIN_ROI_SIDE = 24\n",
        "FALLBACK = \"center\"                   # \"center\" or \"full\"\n",
        "\n",
        "# DINO normalization (ImageNet)\n",
        "IMNET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMNET_STD  = (0.229, 0.224, 0.225)\n",
        "\n",
        "# ----------------------------\n",
        "# Load DINOv2\n",
        "# ----------------------------\n",
        "model = torch.hub.load(\"facebookresearch/dinov2\", DINO_MODEL).to(DEVICE).eval()\n",
        "\n",
        "# ----------------------------\n",
        "# ROI helpers\n",
        "# ----------------------------\n",
        "def normalize01(img2d):\n",
        "    img2d = img2d.astype(np.float32)\n",
        "    p1, p99 = np.percentile(img2d, (1, 99))\n",
        "    return np.clip((img2d - p1) / (p99 - p1 + 1e-6), 0, 1)\n",
        "\n",
        "def clip_box(y0, x0, y1, x1, H, W):\n",
        "    y0 = max(0, int(y0)); x0 = max(0, int(x0))\n",
        "    y1 = min(H, int(y1)); x1 = min(W, int(x1))\n",
        "    if y1 <= y0: y1 = min(H, y0 + 1)\n",
        "    if x1 <= x0: x1 = min(W, x0 + 1)\n",
        "    return y0, x0, y1, x1\n",
        "\n",
        "def ensure_min_side(y0, x0, y1, x1, H, W, min_side=24):\n",
        "    h = y1 - y0\n",
        "    w = x1 - x0\n",
        "    if h >= min_side and w >= min_side:\n",
        "        return y0, x0, y1, x1\n",
        "    cy = (y0 + y1) // 2\n",
        "    cx = (x0 + x1) // 2\n",
        "    half = max(min_side // 2, max(h, w) // 2)\n",
        "    return clip_box(cy-half, cx-half, cy+half, cx+half, H, W)\n",
        "\n",
        "def center_box(H, W, side=None):\n",
        "    if side is None:\n",
        "        side = min(H, W)\n",
        "    side = min(side, H, W)\n",
        "    y0 = (H - side) // 2\n",
        "    x0 = (W - side) // 2\n",
        "    return y0, x0, y0 + side, x0 + side\n",
        "\n",
        "def roi_from_mask(img2d, seg, margin=20, min_side=24, defect_classes=(1,2,3), fallback=\"center\"):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      roi_uint8_rgb: HxWx3 uint8\n",
        "      box: (y0,x0,y1,x1)\n",
        "      used_defect_roi: bool\n",
        "    \"\"\"\n",
        "    H, W = img2d.shape\n",
        "    m = np.isin(seg, defect_classes)\n",
        "    if np.any(m):\n",
        "        ys, xs = np.where(m)\n",
        "        y0 = ys.min() - margin\n",
        "        y1 = ys.max() + margin + 1\n",
        "        x0 = xs.min() - margin\n",
        "        x1 = xs.max() + margin + 1\n",
        "        y0, x0, y1, x1 = clip_box(y0, x0, y1, x1, H, W)\n",
        "        y0, x0, y1, x1 = ensure_min_side(y0, x0, y1, x1, H, W, min_side=min_side)\n",
        "        crop = normalize01(img2d[y0:y1, x0:x1])\n",
        "        crop_u8 = (crop * 255.0 + 0.5).astype(np.uint8)\n",
        "        roi = np.repeat(crop_u8[..., None], 3, axis=-1)  # RGB uint8\n",
        "        return roi, (y0, x0, y1, x1), True\n",
        "\n",
        "    # fallback\n",
        "    if fallback == \"full\":\n",
        "        y0, x0, y1, x1 = 0, 0, H, W\n",
        "    else:\n",
        "        y0, x0, y1, x1 = center_box(H, W, side=min(H, W))\n",
        "    crop = normalize01(img2d[y0:y1, x0:x1])\n",
        "    crop_u8 = (crop * 255.0 + 0.5).astype(np.uint8)\n",
        "    roi = np.repeat(crop_u8[..., None], 3, axis=-1)\n",
        "    return roi, (y0, x0, y1, x1), False\n",
        "\n",
        "# ----------------------------\n",
        "# Torch preprocessing WITHOUT numpy bridge\n",
        "# ----------------------------\n",
        "def pil_to_tensor_no_numpy(pil_img: Image.Image) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Returns float tensor CHW in [0,1] using ByteStorage.from_buffer (no torch.from_numpy).\n",
        "    \"\"\"\n",
        "    pil_img = pil_img.convert(\"RGB\")\n",
        "    w, h = pil_img.size\n",
        "    b = pil_img.tobytes()  # bytes\n",
        "    storage = torch.ByteStorage.from_buffer(b)\n",
        "    x = torch.ByteTensor(storage).view(h, w, 3).permute(2, 0, 1).contiguous()\n",
        "    return x.float().div_(255.0)\n",
        "\n",
        "def preprocess_rgb_u8_batch(rgb_u8_list, out_size=224, device=\"cuda\"):\n",
        "    \"\"\"\n",
        "    rgb_u8_list: list of HxWx3 uint8 numpy arrays\n",
        "    Returns: torch tensor (B,3,out_size,out_size) normalized for DINO\n",
        "    \"\"\"\n",
        "    tensors = []\n",
        "    for arr in rgb_u8_list:\n",
        "        # build PIL without torch/torchvision tensor conversion\n",
        "        h, w, _ = arr.shape\n",
        "        pil = Image.frombytes(\"RGB\", (w, h), arr.tobytes())\n",
        "        t = pil_to_tensor_no_numpy(pil)  # (3,H,W) float\n",
        "        tensors.append(t)\n",
        "\n",
        "    x = torch.stack(tensors, dim=0)  # CPU float\n",
        "    # resize to PATCH_SIZE using torch only\n",
        "    x = F.interpolate(x, size=(out_size, out_size), mode=\"bicubic\", align_corners=False)\n",
        "\n",
        "    # normalize\n",
        "    mean = torch.tensor(IMNET_MEAN, dtype=x.dtype).view(1, 3, 1, 1)\n",
        "    std  = torch.tensor(IMNET_STD,  dtype=x.dtype).view(1, 3, 1, 1)\n",
        "    x = (x - mean) / std\n",
        "\n",
        "    return x.to(device, non_blocking=True)\n",
        "\n",
        "@torch.inference_mode()\n",
        "def embed_batch_rgb_u8(rgb_u8_list):\n",
        "    batch = preprocess_rgb_u8_batch(rgb_u8_list, out_size=PATCH_SIZE, device=DEVICE)\n",
        "    feats = model.forward_features(batch)[\"x_norm_patchtokens\"]\n",
        "    emb = feats.mean(dim=1).cpu().numpy()\n",
        "    return emb\n",
        "\n",
        "# ----------------------------\n",
        "# Main: compute ROI embeddings\n",
        "# ----------------------------\n",
        "with h5py.File(h5_in, \"r\") as fin, h5py.File(h5_masks, \"r\") as fmask, h5py.File(h5_out, \"w\") as fout:\n",
        "    imgs = fin[\"images\"]\n",
        "    segs = fmask[\"seg\"]\n",
        "    labels = fin[\"labels\"][:] if \"labels\" in fin else None\n",
        "    n = len(imgs)\n",
        "\n",
        "    emb_dim = 768  # dinov2_vitb14\n",
        "    emb_ds = fout.create_dataset(\"embeddings\", shape=(n, emb_dim), dtype=\"float32\", compression=\"gzip\")\n",
        "\n",
        "    if labels is not None:\n",
        "        fout.create_dataset(\"labels\", data=labels)\n",
        "\n",
        "    roi_box_ds = fout.create_dataset(\"roi_box_y0x0y1x1\", shape=(n, 4), dtype=\"int32\")\n",
        "    roi_used_ds = fout.create_dataset(\"roi_used_defect\", shape=(n,), dtype=\"uint8\")\n",
        "\n",
        "    for k in [\"meta/paths\", \"meta/label_names\"]:\n",
        "        if k in fin:\n",
        "            fout.create_dataset(k, data=fin[k][:])\n",
        "\n",
        "    buf = []\n",
        "    idxs = []\n",
        "\n",
        "    for i in range(n):\n",
        "        img2d = imgs[i]\n",
        "        seg = segs[i]\n",
        "\n",
        "        roi_rgb_u8, box, used = roi_from_mask(\n",
        "            img2d, seg,\n",
        "            margin=ROI_MARGIN,\n",
        "            min_side=MIN_ROI_SIDE,\n",
        "            defect_classes=DEFECT_CLASSES,\n",
        "            fallback=FALLBACK\n",
        "        )\n",
        "\n",
        "        roi_box_ds[i] = np.array(box, dtype=np.int32)\n",
        "        roi_used_ds[i] = np.uint8(1 if used else 0)\n",
        "\n",
        "        buf.append(roi_rgb_u8)\n",
        "        idxs.append(i)\n",
        "\n",
        "        if len(buf) == batch_size or i == n - 1:\n",
        "            emb = embed_batch_rgb_u8(buf)\n",
        "            emb_ds[idxs[0]:idxs[0] + len(buf)] = emb\n",
        "            buf, idxs = [], []\n",
        "\n",
        "print(\"Saved ROI embeddings to\", h5_out)\n",
        "\n",
        "# ----------------------------\n",
        "# Quick sanity stats\n",
        "# ----------------------------\n",
        "with h5py.File(h5_out, \"r\") as f:\n",
        "    emb = f[\"embeddings\"][:]\n",
        "    used = f[\"roi_used_defect\"][:]\n",
        "    labels = f[\"labels\"][:] if \"labels\" in f else None\n",
        "    names = [x.decode() for x in f[\"meta/label_names\"][:]] if \"meta/label_names\" in f else None\n",
        "\n",
        "print(\"ROI used (defect-based) fraction:\", float(used.mean()))\n",
        "if labels is not None and names is not None:\n",
        "    for lid in np.unique(labels):\n",
        "        m = emb[labels == lid].mean()\n",
        "        s = emb[labels == lid].std()\n",
        "        frac = float(used[labels == lid].mean())\n",
        "        print(f\"{names[int(lid)]:>20s} | emb mean {m:.4f} std {s:.4f} | defect-ROI frac {frac:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Jupyter cell: MASK-FREE DINOv2 embeddings (top-k patch pooling) + analysis (UMAP + top-k sweep) + optional ROI vs no-mask comparison\n",
        "# - No masks/ROI required\n",
        "# - Avoids torch->numpy bridge (RuntimeError: Numpy is not available) by using .tolist() conversion\n",
        "# - Produces: sto_embeddings_nomask_k32.h5 (and optionally multiple ks)\n",
        "# - Analysis:\n",
        "#   (A) Per-class embedding stats (if labels + meta/label_names exist)\n",
        "#   (B) UMAP 2D visualization (uses umap-learn; will fall back to PCA if missing)\n",
        "#   (C) Top-k sensitivity sweep: k in {8,16,32,64}\n",
        "#   (D) ROI vs no-mask UMAP comparison if sto_embeddings_roi.h5 exists\n",
        "\n",
        "import os, h5py, numpy as np, torch\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "\n",
        "# ----------------------------\n",
        "# Config\n",
        "# ----------------------------\n",
        "DINO_MODEL = \"dinov2_vitb14\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "PATCH_SIZE = 224\n",
        "batch_size = 64  # lower to reduce CPU <-> GPU overhead and .tolist() cost\n",
        "\n",
        "h5_in = \"sto_dataset.h5\"\n",
        "\n",
        "# main output (single-k run)\n",
        "TOPK_MAIN = 32\n",
        "h5_out_main = f\"sto_embeddings_nomask_k{TOPK_MAIN}.h5\"\n",
        "\n",
        "# sweep settings (set to None to disable)\n",
        "TOPK_SWEEP = [8, 16, 32, 64]   # comment out to disable sweep\n",
        "DO_SWEEP = True\n",
        "\n",
        "# optional comparison file (if it exists)\n",
        "h5_roi = \"sto_embeddings_roi.h5\"\n",
        "DO_ROI_COMPARE = os.path.exists(h5_roi)\n",
        "\n",
        "# If you want to downsample for faster UMAP visualization\n",
        "MAX_POINTS_FOR_UMAP = 4000\n",
        "\n",
        "# DINO normalization (ImageNet)\n",
        "IMNET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMNET_STD  = (0.229, 0.224, 0.225)\n",
        "\n",
        "# ----------------------------\n",
        "# Load DINOv2\n",
        "# ----------------------------\n",
        "model = torch.hub.load(\"facebookresearch/dinov2\", DINO_MODEL).to(DEVICE).eval()\n",
        "\n",
        "# ----------------------------\n",
        "# Helpers\n",
        "# ----------------------------\n",
        "def normalize01(img2d):\n",
        "    img2d = img2d.astype(np.float32)\n",
        "    p1, p99 = np.percentile(img2d, (1, 99))\n",
        "    return np.clip((img2d - p1) / (p99 - p1 + 1e-6), 0, 1)\n",
        "\n",
        "def pil_to_tensor_no_numpy(pil_img: Image.Image) -> torch.Tensor:\n",
        "    # returns float tensor CHW in [0,1] using ByteStorage.from_buffer (no torch.from_numpy)\n",
        "    pil_img = pil_img.convert(\"RGB\")\n",
        "    w, h = pil_img.size\n",
        "    b = pil_img.tobytes()\n",
        "    storage = torch.ByteStorage.from_buffer(b)\n",
        "    x = torch.ByteTensor(storage).view(h, w, 3).permute(2, 0, 1).contiguous()\n",
        "    return x.float().div_(255.0)\n",
        "\n",
        "def preprocess_gray2d_to_dino(img2d, out_size=224):\n",
        "    g01 = normalize01(img2d)\n",
        "    u8 = (g01 * 255.0 + 0.5).astype(np.uint8)\n",
        "    rgb = np.repeat(u8[..., None], 3, axis=-1)  # HxWx3 uint8\n",
        "\n",
        "    h, w, _ = rgb.shape\n",
        "    pil = Image.frombytes(\"RGB\", (w, h), rgb.tobytes())\n",
        "    x = pil_to_tensor_no_numpy(pil).unsqueeze(0)  # (1,3,H,W)\n",
        "\n",
        "    x = F.interpolate(x, size=(out_size, out_size), mode=\"bicubic\", align_corners=False)\n",
        "\n",
        "    mean = torch.tensor(IMNET_MEAN, dtype=x.dtype).view(1, 3, 1, 1)\n",
        "    std  = torch.tensor(IMNET_STD,  dtype=x.dtype).view(1, 3, 1, 1)\n",
        "    x = (x - mean) / std\n",
        "    return x\n",
        "\n",
        "@torch.inference_mode()\n",
        "def embed_batch_topk_torch(img2d_list, topk=32):\n",
        "    xs = [preprocess_gray2d_to_dino(im, out_size=PATCH_SIZE) for im in img2d_list]\n",
        "    x = torch.cat(xs, dim=0).to(DEVICE, non_blocking=True)  # (B,3,224,224)\n",
        "\n",
        "    feats = model.forward_features(x)[\"x_norm_patchtokens\"]  # (B, N, D)\n",
        "    score = torch.linalg.norm(feats, dim=-1)                # (B, N)\n",
        "    k = min(int(topk), feats.shape[1])\n",
        "    idx = torch.topk(score, k=k, dim=1, largest=True).indices  # (B, k)\n",
        "\n",
        "    B, N, D = feats.shape\n",
        "    idx_exp = idx.unsqueeze(-1).expand(B, k, D)\n",
        "    top_tokens = torch.gather(feats, dim=1, index=idx_exp)  # (B,k,D)\n",
        "    emb = top_tokens.mean(dim=1)                            # (B,D)\n",
        "\n",
        "    return emb.detach().to(\"cpu\", non_blocking=False).float().contiguous()\n",
        "\n",
        "def write_embeddings_nomask(h5_out, topk):\n",
        "    with h5py.File(h5_in, \"r\") as fin, h5py.File(h5_out, \"w\") as fout:\n",
        "        imgs = fin[\"images\"]\n",
        "        labels = fin[\"labels\"][:] if \"labels\" in fin else None\n",
        "        n = len(imgs)\n",
        "\n",
        "        emb_dim = 768  # vitb14\n",
        "        emb_ds = fout.create_dataset(\"embeddings\", shape=(n, emb_dim), dtype=\"float32\", compression=\"gzip\")\n",
        "        if labels is not None:\n",
        "            fout.create_dataset(\"labels\", data=labels)\n",
        "\n",
        "        for k in [\"meta/paths\", \"meta/label_names\"]:\n",
        "            if k in fin:\n",
        "                fout.create_dataset(k, data=fin[k][:])\n",
        "\n",
        "        buf, idxs = [], []\n",
        "        for i in range(n):\n",
        "            buf.append(imgs[i])\n",
        "            idxs.append(i)\n",
        "            if len(buf) == batch_size or i == n - 1:\n",
        "                emb_t = embed_batch_topk_torch(buf, topk=topk)               # torch CPU tensor\n",
        "                emb_np = np.asarray(emb_t.tolist(), dtype=np.float32)        # no torch->numpy bridge\n",
        "                emb_ds[idxs[0]:idxs[0] + len(buf)] = emb_np\n",
        "                buf, idxs = [], []\n",
        "    print(f\"[OK] Saved mask-free embeddings: {h5_out} (topk={topk})\")\n",
        "\n",
        "def load_embeddings(h5_path):\n",
        "    with h5py.File(h5_path, \"r\") as f:\n",
        "        emb = f[\"embeddings\"][:]\n",
        "        labels = f[\"labels\"][:] if \"labels\" in f else None\n",
        "        names = [x.decode() for x in f[\"meta/label_names\"][:]] if \"meta/label_names\" in f else None\n",
        "    return emb, labels, names\n",
        "\n",
        "def per_class_stats(emb, labels, names, title=\"\"):\n",
        "    if title:\n",
        "        print(\"\\n\" + title)\n",
        "    print(\"Embeddings shape:\", emb.shape, \"dtype:\", emb.dtype)\n",
        "    print(\"Global mean:\", float(emb.mean()), \"Global std:\", float(emb.std()))\n",
        "    if labels is None or names is None:\n",
        "        print(\"No labels and/or label_names found -> skipping per-class stats.\")\n",
        "        return\n",
        "    print(\"\\nPer-class stats:\")\n",
        "    for lid in np.unique(labels):\n",
        "        m = float(emb[labels == lid].mean())\n",
        "        s = float(emb[labels == lid].std())\n",
        "        n = int((labels == lid).sum())\n",
        "        print(f\"{names[int(lid)]:>20s} | n={n:5d} | mean={m:.4f} | std={s:.4f}\")\n",
        "\n",
        "def sample_for_viz(X, y=None, max_points=4000, seed=0):\n",
        "    n = len(X)\n",
        "    if n <= max_points:\n",
        "        return X, y\n",
        "    rng = np.random.default_rng(seed)\n",
        "    idx = rng.choice(n, size=max_points, replace=False)\n",
        "    return X[idx], (y[idx] if y is not None else None)\n",
        "\n",
        "def umap_or_pca_2d(X, seed=0):\n",
        "    # Try UMAP; if unavailable, fall back to PCA\n",
        "    try:\n",
        "        import umap\n",
        "        reducer = umap.UMAP(n_components=2, random_state=seed, n_neighbors=30, min_dist=0.05)\n",
        "        Z = reducer.fit_transform(X)\n",
        "        method = \"UMAP\"\n",
        "        return Z, method\n",
        "    except Exception as e:\n",
        "        from sklearn.decomposition import PCA\n",
        "        Z = PCA(n_components=2, random_state=seed).fit_transform(X)\n",
        "        method = \"PCA (fallback; install umap-learn for UMAP)\"\n",
        "        return Z, method\n",
        "\n",
        "def plot_2d(Z, labels=None, names=None, title=\"2D embedding\"):\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.figure(figsize=(7, 6))\n",
        "    if labels is None:\n",
        "        plt.scatter(Z[:, 0], Z[:, 1], s=4)\n",
        "    else:\n",
        "        # plot each class separately for readability\n",
        "        for lid in np.unique(labels):\n",
        "            m = labels == lid\n",
        "            lab = names[int(lid)] if names is not None and int(lid) < len(names) else str(int(lid))\n",
        "            plt.scatter(Z[m, 0], Z[m, 1], s=4, label=lab)\n",
        "        plt.legend(markerscale=3, fontsize=8)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"dim-1\")\n",
        "    plt.ylabel(\"dim-2\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def simple_separation_score(Z, labels):\n",
        "    # quick numeric proxy: ratio of between-class centroid variance to within-class variance\n",
        "    if labels is None:\n",
        "        return np.nan\n",
        "    labs = np.unique(labels)\n",
        "    centroids = []\n",
        "    within = []\n",
        "    for lid in labs:\n",
        "        Xc = Z[labels == lid]\n",
        "        centroids.append(Xc.mean(axis=0))\n",
        "        within.append(((Xc - Xc.mean(axis=0))**2).sum(axis=1).mean())\n",
        "    centroids = np.stack(centroids, axis=0)\n",
        "    between = ((centroids - centroids.mean(axis=0))**2).sum(axis=1).mean()\n",
        "    within = float(np.mean(within))\n",
        "    return float(between / (within + 1e-12))\n",
        "\n",
        "# ----------------------------\n",
        "# 1) Generate embeddings (single-k)\n",
        "# ----------------------------\n",
        "write_embeddings_nomask(h5_out_main, TOPK_MAIN)\n",
        "\n",
        "# ----------------------------\n",
        "# 2) Sanity stats + UMAP/PCA plot for main file\n",
        "# ----------------------------\n",
        "emb, labels, names = load_embeddings(h5_out_main)\n",
        "per_class_stats(emb, labels, names, title=f\"=== MASK-FREE Embeddings (topk={TOPK_MAIN}) ===\")\n",
        "\n",
        "Xviz, yviz = sample_for_viz(emb, labels, max_points=MAX_POINTS_FOR_UMAP, seed=0)\n",
        "Z, method = umap_or_pca_2d(Xviz, seed=0)\n",
        "score = simple_separation_score(Z, yviz) if yviz is not None else np.nan\n",
        "plot_2d(Z, yviz, names, title=f\"{method} of MASK-FREE embeddings (topk={TOPK_MAIN}) | sep={score:.3f}\")\n",
        "\n",
        "# ----------------------------\n",
        "# 3) Top-k sensitivity sweep (optional)\n",
        "#    - regenerates embeddings for each k\n",
        "#    - computes UMAP/PCA sep score (quick proxy)\n",
        "# ----------------------------\n",
        "if DO_SWEEP and TOPK_SWEEP is not None:\n",
        "    print(\"\\n=== TOP-K SENSITIVITY SWEEP ===\")\n",
        "    sweep_results = []\n",
        "    for k in TOPK_SWEEP:\n",
        "        outk = f\"sto_embeddings_nomask_k{k}.h5\"\n",
        "        if not os.path.exists(outk):\n",
        "            write_embeddings_nomask(outk, k)\n",
        "        Ek, yk, nk = load_embeddings(outk)\n",
        "\n",
        "        Xk, yk_v = sample_for_viz(Ek, yk, max_points=MAX_POINTS_FOR_UMAP, seed=0)\n",
        "        Zk, methodk = umap_or_pca_2d(Xk, seed=0)\n",
        "        sepk = simple_separation_score(Zk, yk_v) if yk_v is not None else np.nan\n",
        "        sweep_results.append((k, sepk, methodk))\n",
        "        print(f\"topk={k:>3d} | {methodk:<40s} | sep={sepk:.4f}\")\n",
        "\n",
        "    # plot sweep curve\n",
        "    import matplotlib.pyplot as plt\n",
        "    ks = [r[0] for r in sweep_results]\n",
        "    ss = [r[1] for r in sweep_results]\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.plot(ks, ss, marker=\"o\")\n",
        "    plt.title(\"Top-k sweep: separation proxy (higher is better)\")\n",
        "    plt.xlabel(\"topk\")\n",
        "    plt.ylabel(\"between/within (2D) proxy\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ----------------------------\n",
        "# 4) ROI vs No-mask comparison (optional)\n",
        "#    - requires sto_embeddings_roi.h5 existing\n",
        "# ----------------------------\n",
        "if DO_ROI_COMPARE:\n",
        "    print(\"\\n=== ROI vs NO-MASK COMPARISON ===\")\n",
        "    emb_roi, lab_roi, names_roi = load_embeddings(h5_roi)\n",
        "\n",
        "    # sample same number of points for fair-ish comparison\n",
        "    max_pts = min(MAX_POINTS_FOR_UMAP, len(emb), len(emb_roi))\n",
        "    Xn, yn = sample_for_viz(emb, labels, max_points=max_pts, seed=1)\n",
        "    Xr, yr = sample_for_viz(emb_roi, lab_roi, max_points=max_pts, seed=1)\n",
        "\n",
        "    Zn, mn = umap_or_pca_2d(Xn, seed=1)\n",
        "    Zr, mr = umap_or_pca_2d(Xr, seed=1)\n",
        "\n",
        "    sn = simple_separation_score(Zn, yn) if yn is not None else np.nan\n",
        "    sr = simple_separation_score(Zr, yr) if yr is not None else np.nan\n",
        "\n",
        "    plot_2d(Zn, yn, names, title=f\"{mn} NO-MASK (topk={TOPK_MAIN}) | sep={sn:.3f}\")\n",
        "    plot_2d(Zr, yr, names_roi, title=f\"{mr} ROI-based | sep={sr:.3f}\")\n",
        "\n",
        "    print(f\"NO-MASK sep={sn:.4f} | ROI sep={sr:.4f}\")\n",
        "else:\n",
        "    print(\"\\n[INFO] ROI comparison skipped (sto_embeddings_roi.h5 not found).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import h5py, numpy as np\n",
        "\n",
        "EMB_H5 = \"sto_embeddings_nomask_k32.h5\"   # you already generated this\n",
        "# (works also for sto_embeddings_roi.h5 if you want to compare)\n",
        "\n",
        "with h5py.File(EMB_H5, \"r\") as f:\n",
        "    X = f[\"embeddings\"][:]                  # (N,768) float32\n",
        "    y_true = f[\"labels\"][:] if \"labels\" in f else None\n",
        "    names = None\n",
        "    if \"meta/label_names\" in f:\n",
        "        names = [x.decode() for x in f[\"meta/label_names\"][:]]\n",
        "\n",
        "print(\"X:\", X.shape, X.dtype)\n",
        "print(\"labels:\", None if y_true is None else y_true.shape)\n",
        "print(\"names:\", names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "scaler = StandardScaler(with_mean=True, with_std=True)\n",
        "Xz = scaler.fit_transform(X)\n",
        "\n",
        "# Optional: keep enough dims for clustering stability (often helps)\n",
        "PCA_DENOISE = 128\n",
        "pca0 = PCA(n_components=min(PCA_DENOISE, Xz.shape[1]), random_state=0)\n",
        "X0 = pca0.fit_transform(Xz)\n",
        "\n",
        "print(\"X0:\", X0.shape, \"explained:\", float(pca0.explained_variance_ratio_.sum()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def corr_filter(X, thr=0.95):\n",
        "    # X: (N,D)\n",
        "    C = np.corrcoef(X, rowvar=False)\n",
        "    C = np.nan_to_num(C, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "    keep = []\n",
        "    removed = np.zeros(C.shape[0], dtype=bool)\n",
        "    for i in range(C.shape[0]):\n",
        "        if removed[i]:\n",
        "            continue\n",
        "        keep.append(i)\n",
        "        # remove highly correlated future dims\n",
        "        j = np.where(np.abs(C[i]) > thr)[0]\n",
        "        j = j[j > i]\n",
        "        removed[j] = True\n",
        "    return np.array(keep, dtype=int)\n",
        "\n",
        "keep_corr = corr_filter(X0, thr=0.95)\n",
        "X1 = X0[:, keep_corr]\n",
        "print(\"after corr filter:\", X1.shape, \"kept:\", len(keep_corr))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "def feature_separation_proxy(X, k=4, seed=0):\n",
        "    km = KMeans(n_clusters=k, n_init=10, random_state=seed).fit(X)\n",
        "    labels = km.labels_\n",
        "    mu = km.cluster_centers_\n",
        "    # between-class variance per dim\n",
        "    between = mu.var(axis=0)\n",
        "    # within-class variance per dim\n",
        "    within = np.zeros(X.shape[1], dtype=np.float64)\n",
        "    for c in range(k):\n",
        "        xc = X[labels == c]\n",
        "        if len(xc) > 1:\n",
        "            within += xc.var(axis=0)\n",
        "    within /= max(1, k)\n",
        "    score = between / (within + 1e-8)\n",
        "    return score\n",
        "\n",
        "proxy = feature_separation_proxy(X1, k=4, seed=0)\n",
        "order = np.argsort(proxy)[::-1]\n",
        "\n",
        "# keep top dims\n",
        "TOP_DIMS = min(64, X1.shape[1])\n",
        "keep_sep = order[:TOP_DIMS]\n",
        "X2 = X1[:, keep_sep]\n",
        "print(\"after sep proxy:\", X2.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "vt = VarianceThreshold(threshold=0.10)\n",
        "X3 = vt.fit_transform(X2)\n",
        "print(\"after variance threshold:\", X3.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# PCA for final clustering space\n",
        "PC_FINAL = min(32, X3.shape[1])\n",
        "pca = PCA(n_components=PC_FINAL, random_state=0)\n",
        "Z = pca.fit_transform(X3)\n",
        "print(\"Z:\", Z.shape, \"explained:\", float(pca.explained_variance_ratio_.sum()))\n",
        "\n",
        "Ks = list(range(2, 9))\n",
        "scores = []\n",
        "models = []\n",
        "for k in Ks:\n",
        "    km = KMeans(n_clusters=k, n_init=20, random_state=0).fit(Z)\n",
        "    s = silhouette_score(Z, km.labels_)\n",
        "    scores.append(s)\n",
        "    models.append(km)\n",
        "    print(f\"k={k:2d}  silhouette={s:.4f}\")\n",
        "\n",
        "best_i = int(np.argmax(scores))\n",
        "best_k = Ks[best_i]\n",
        "best_km = models[best_i]\n",
        "pred = best_km.labels_\n",
        "print(\"\\nBEST k =\", best_k, \"silhouette =\", scores[best_i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# t-SNE\n",
        "from sklearn.manifold import TSNE\n",
        "ts = TSNE(n_components=2, perplexity=30, init=\"pca\", learning_rate=\"auto\", random_state=0)\n",
        "Y = ts.fit_transform(Z)\n",
        "\n",
        "plt.figure(figsize=(7,6))\n",
        "plt.scatter(Y[:,0], Y[:,1], c=pred, s=8, cmap=\"tab10\")\n",
        "plt.title(f\"t-SNE of DINO embeddings (k={best_k})\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# Optional: if true labels exist, show cluster-vs-label table\n",
        "if y_true is not None and names is not None:\n",
        "    import pandas as pd\n",
        "    C = np.zeros((best_k, len(names)), dtype=int)\n",
        "    for i in range(len(pred)):\n",
        "        C[pred[i], int(y_true[i])] += 1\n",
        "    df = pd.DataFrame(C, columns=names)\n",
        "    display(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# ---- assumes you already have:\n",
        "# X (N,768), y_true (N,), names (list), and Z (N,32) from your previous run\n",
        "\n",
        "# 1) compute bulk centroid in ORIGINAL embedding space (X)\n",
        "bulk_id = names.index(\"Bulk\")\n",
        "X_bulk = X[y_true == bulk_id].astype(np.float32)\n",
        "\n",
        "# L2 normalize for cosine\n",
        "def l2norm_rows(A, eps=1e-8):\n",
        "    n = np.linalg.norm(A, axis=1, keepdims=True)\n",
        "    return A / (n + eps)\n",
        "\n",
        "Xn = l2norm_rows(X.astype(np.float32))\n",
        "bulk_centroid = Xn[y_true == bulk_id].mean(axis=0)\n",
        "bulk_centroid = bulk_centroid / (np.linalg.norm(bulk_centroid) + 1e-8)\n",
        "\n",
        "# 2) anomaly score = cosine distance to bulk centroid\n",
        "cos_sim = (Xn * bulk_centroid[None, :]).sum(axis=1)          # in [-1,1]\n",
        "anomaly = (1.0 - cos_sim).astype(np.float32)                 # in [0,2] approx\n",
        "\n",
        "print(\"anomaly stats:\", float(anomaly.min()), float(anomaly.mean()), float(anomaly.max()))\n",
        "\n",
        "# 3) append anomaly to Z (your PCA space)\n",
        "Z_aug = np.concatenate([Z, anomaly[:, None]], axis=1).astype(np.float32)\n",
        "print(\"Z_aug:\", Z_aug.shape)\n",
        "\n",
        "# 4) re-run k sweep\n",
        "Ks = list(range(2, 9))\n",
        "scores = []\n",
        "models = []\n",
        "for k in Ks:\n",
        "    km = KMeans(n_clusters=k, n_init=30, random_state=0).fit(Z_aug)\n",
        "    s = silhouette_score(Z_aug, km.labels_)\n",
        "    scores.append(s)\n",
        "    models.append(km)\n",
        "    print(f\"k={k:2d}  silhouette={s:.4f}\")\n",
        "\n",
        "best_i = int(np.argmax(scores))\n",
        "best_k = Ks[best_i]\n",
        "pred_aug = models[best_i].labels_\n",
        "print(\"\\nBEST k =\", best_k, \"silhouette =\", scores[best_i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "C = np.zeros((best_k, len(names)), dtype=int)\n",
        "for i in range(len(pred_aug)):\n",
        "    C[pred_aug[i], int(y_true[i])] += 1\n",
        "\n",
        "df = pd.DataFrame(C, columns=names)\n",
        "display(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "ts = TSNE(n_components=2, perplexity=30, init=\"pca\", learning_rate=\"auto\", random_state=0)\n",
        "Y = ts.fit_transform(Z_aug)\n",
        "\n",
        "plt.figure(figsize=(7,6))\n",
        "plt.scatter(Y[:,0], Y[:,1], c=pred_aug, s=8, cmap=\"tab10\")\n",
        "plt.title(f\"t-SNE of DINO embeddings + bulk-anomaly (k={best_k})\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "cl = AgglomerativeClustering(\n",
        "    n_clusters=4,\n",
        "    metric=\"cosine\",\n",
        "    linkage=\"average\"\n",
        ")\n",
        "pred_cos = cl.fit_predict(Z_aug)\n",
        "\n",
        "print(\"silhouette (cosine agglo):\",\n",
        "      silhouette_score(Z_aug, pred_cos, metric=\"cosine\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyO2ZH6U5ktfe5cHj3mMTxQC",
      "include_colab_link": true,
      "provenance": [],
      "runtime_attributes": {
        "runtime_version": "2025.07"
      }
    },
    "kernelspec": {
      "display_name": "dinov2-extras",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
