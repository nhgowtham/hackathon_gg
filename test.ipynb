{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nhgowtham/hackathon_gg/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWMFYqt6KvIS"
      },
      "source": [
        "## Dataset download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4O3ZV14ZIM16",
        "outputId": "598631ed-77e5-46d2-aa17-f224fc684b5a"
      },
      "outputs": [],
      "source": [
        "# https://drive.google.com/drive/folders/1u0z4pkZJN8Q00zt_QyEWHpckuFJ_z3iZ?usp=drive_link\n",
        "\n",
        "#  Graphere dataset\n",
        "!gdown --folder https://drive.google.com/drive/folders/1u0z4pkZJN8Q00zt_QyEWHpckuFJ_z3iZ -O data/\n",
        "\n",
        "\n",
        "# https://drive.google.com/drive/folders/1DTMrT_Ihpuopwny63f4OwjwPTPtXmiy2?usp=drive_link\n",
        "# CoAg\n",
        "!gdown --folder https://drive.google.com/drive/folders/1DTMrT_Ihpuopwny63f4OwjwPTPtXmiy2 -O data/\n",
        "\n",
        "\n",
        "# https://drive.google.com/drive/folders/18BkhR-fbuuavqN7LAtrvWeJmxP-p2WXS?usp=drive_link\n",
        "#MoS2_Nanowire\n",
        "!gdown --folder https://drive.google.com/drive/folders/18BkhR-fbuuavqN7LAtrvWeJmxP-p2WXS -O data/\n",
        "\n",
        "# https://drive.google.com/drive/folders/1mkY9KlfnZXsvFfHLFujNmMPx4YTE0yxD?usp=drive_link\n",
        "# MoS2 monolayer\n",
        "!gdown --folder https://drive.google.com/drive/folders/1mkY9KlfnZXsvFfHLFujNmMPx4YTE0yxD -O data/\n",
        "\n",
        "# https://drive.google.com/drive/folders/1qUwUopeyzAXqVQ3ROs3XEBmW9yY9Yrn6?usp=drive_link\n",
        "# EELS\n",
        "!gdown --folder https://drive.google.com/drive/folders/1qUwUopeyzAXqVQ3ROs3XEBmW9yY9Yrn6 -O data/\n",
        "\n",
        "\n",
        "# https://drive.google.com/drive/folders/1lwFqZnVGk0qjoRYeKAJoNuI90vm7Nnos?usp=drive_link\n",
        "# SnSe dataset\n",
        "!gdown --folder https://drive.google.com/drive/folders/1lwFqZnVGk0qjoRYeKAJoNuI90vm7Nnos -O data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-113AkRd098"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install -q pyro5\n",
        "!pip install -q scifireaders\n",
        "!pip install -q sidpy\n",
        "!pip install -q pynsid\n",
        "!pip install -q git+https://github.com/pycroscopy/DTMicroscope.git\n",
        "!pip install pytemlib\n",
        "!pip install -q git+https://github.com/pycroscopy/DTMicroscope.git@utk\n",
        "!pip install git+https://github.com/facebookresearch/segment-anything.git\n",
        "!pip install torch torchvision\n",
        "!pip install matplotlib\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3K_0ID2K4Gb"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Path to the combined dataset file\n",
        "combined_h5_path = \"combined_dataset.h5\"\n",
        "\n",
        "def list_all_datasets(h5file):\n",
        "    paths = []\n",
        "    def visitor(name, obj):\n",
        "        if isinstance(obj, h5py.Dataset):\n",
        "            paths.append(name)\n",
        "    h5file.visititems(visitor)\n",
        "    return paths\n",
        "\n",
        "def extract_preview(dataset):\n",
        "    arr = dataset[()]\n",
        "    while arr.ndim > 2:\n",
        "        arr = arr[arr.shape[0] // 2]\n",
        "    return np.squeeze(arr)\n",
        "\n",
        "def show_image(image, title):\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Open and visualize\n",
        "with h5py.File(combined_h5_path, \"r\") as f:\n",
        "    all_datasets = list_all_datasets(f)\n",
        "\n",
        "    for path in all_datasets:\n",
        "        try:\n",
        "            dset = f[path]\n",
        "            shape = dset.shape\n",
        "            if dset.ndim >= 2:\n",
        "                preview = extract_preview(dset)\n",
        "                print(f\"[OK] {path} â†’ shape = {shape}\")\n",
        "                show_image(preview, f\"{path}\\nshape={shape}\")\n",
        "        except Exception as e:\n",
        "            print(f\"[ERROR] {path}: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzoMSt-1K37h"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from dinov2.data.transforms import make_classification_eval_transform\n",
        "import os\n",
        "\n",
        "# Constants\n",
        "DINO_MODEL = \"dinov2_vitb14\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "PATCH_SIZE = 224\n",
        "STRIDE = 112\n",
        "H5_PATH = \"combined_dataset.h5\"\n",
        "OUTPUT_H5 = \"dinov2_embeddings.h5\"\n",
        "\n",
        "# Load DINOv2 model and transform\n",
        "model = torch.hub.load(\"facebookresearch/dinov2\", DINO_MODEL).to(DEVICE).eval()\n",
        "transform = make_classification_eval_transform()\n",
        "\n",
        "def normalize_percentile(img, pmin=2, pmax=98):\n",
        "    lo, hi = np.percentile(img, (pmin, pmax))\n",
        "    return np.clip((img - lo) / (hi - lo), 0, 1)\n",
        "\n",
        "def tile_image(image, patch_size=PATCH_SIZE, stride=STRIDE):\n",
        "    h, w = image.shape\n",
        "    patches, positions = [], []\n",
        "    for i in range(0, h - patch_size + 1, stride):\n",
        "        for j in range(0, w - patch_size + 1, stride):\n",
        "            patch = image[i:i+patch_size, j:j+patch_size]\n",
        "            patches.append(patch)\n",
        "            positions.append((i, j))\n",
        "    return patches, positions\n",
        "\n",
        "def extract_embeddings(patches: list[np.ndarray], model, transform):\n",
        "    if len(patches) == 0:\n",
        "        return []\n",
        "    tensor_batch = torch.stack([\n",
        "        transform(Image.fromarray((p * 255).astype(np.uint8)).convert(\"RGB\")) for p in patches\n",
        "    ])\n",
        "    with torch.no_grad():\n",
        "        feats = model.forward_features(tensor_batch.to(DEVICE))[\"x_norm_patchtokens\"]\n",
        "        embeddings = feats.mean(dim=1).cpu().numpy()\n",
        "    return embeddings\n",
        "\n",
        "def process_h5_image(image_array):\n",
        "    img = normalize_percentile(image_array)\n",
        "    patches, positions = tile_image(img)\n",
        "    if len(patches) == 0:\n",
        "        raise ValueError(\"No patches extracted from image\")\n",
        "    embeddings = extract_embeddings(patches, model, transform)\n",
        "    return embeddings, positions, img\n",
        "\n",
        "def extract_preview(dataset):\n",
        "    try:\n",
        "        arr = np.array(dataset)\n",
        "        while arr.ndim > 2:\n",
        "            arr = arr[arr.shape[0] // 2]\n",
        "        return np.squeeze(arr).astype(np.float32)\n",
        "    except Exception as e:\n",
        "        print(f\"[extract_preview ERROR] {dataset.name}: {e}\")\n",
        "        raise\n",
        "\n",
        "def list_all_valid_datasets(h5file):\n",
        "    paths = []\n",
        "    def visitor(name, obj):\n",
        "        if isinstance(obj, h5py.Dataset) and obj.ndim == 2 and min(obj.shape) >= PATCH_SIZE:\n",
        "            paths.append(name)\n",
        "    h5file.visititems(visitor)\n",
        "    return paths\n",
        "\n",
        "# Save embeddings and positions\n",
        "def save_to_hdf5(h5_file, group_name, embeddings, positions, image):\n",
        "    grp = h5_file.require_group(group_name)\n",
        "    grp.create_dataset(\"embeddings\", data=embeddings, compression=\"gzip\")\n",
        "    grp.create_dataset(\"positions\", data=np.array(positions), compression=\"gzip\")\n",
        "    grp.create_dataset(\"image\", data=image.astype(np.float32), compression=\"gzip\")  # <- Add image save\n",
        "\n",
        "\n",
        "# Main loop\n",
        "with h5py.File(H5_PATH, \"r\") as f_in, h5py.File(OUTPUT_H5, \"a\") as f_out:\n",
        "    valid_paths = list_all_valid_datasets(f_in)\n",
        "\n",
        "    for path in valid_paths:\n",
        "        try:\n",
        "            dset = f_in[path]\n",
        "            img = extract_preview(dset)\n",
        "\n",
        "            print(f\"[PROCESSING] {path} with shape {img.shape}\")\n",
        "            emb, pos, img_norm = process_h5_image(img)\n",
        "            save_to_hdf5(f_out, path.replace(\"/\", \"_\"), emb, pos, img_norm)\n",
        "            print(f\"Saved {len(emb)} embeddings for {path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"[ERROR] {path}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "EMB_H5 = \"dinov2_embeddings.h5\"\n",
        "KEYWORD = \"Graphene\"  # <-- Change to \"MoS2\" or \"Graphene\" etc.\n",
        "\n",
        "def load_embeddings_for_subset(h5_path, keyword):\n",
        "    embeddings = []\n",
        "    labels = []\n",
        "    with h5py.File(h5_path, \"r\") as f:\n",
        "        for key in f:\n",
        "            if keyword.lower() in key.lower():\n",
        "                data = f[key][\"embeddings\"][()]\n",
        "                embeddings.append(data)\n",
        "                labels.extend([key] * len(data))\n",
        "    if embeddings:\n",
        "        all_embeddings = np.concatenate(embeddings, axis=0)\n",
        "        return all_embeddings, labels\n",
        "    else:\n",
        "        raise ValueError(f\"No entries found for keyword: {keyword}\")\n",
        "\n",
        "# Load + PCA\n",
        "X, labels = load_embeddings_for_subset(EMB_H5, KEYWORD)\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(X_pca[:, 0], X_pca[:, 1], s=5, alpha=0.7)\n",
        "plt.title(f\"PCA of DINOv2 Embeddings - {KEYWORD}\")\n",
        "plt.xlabel(\"PC1\")\n",
        "plt.ylabel(\"PC2\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.manifold import TSNE\n",
        "import umap\n",
        "import os\n",
        "\n",
        "\n",
        "# === CONFIGURATION ===\n",
        "H5_PATH = \"dinov2_embeddings.h5\"  # Embeddings saved here by earlier step\n",
        "OUTPUT_DIR = \"viz_outputs\"\n",
        "TARGET_MATERIAL = \"SnSe\"  # or 'MoS2', 'Graphene', etc.\n",
        "N_COMPONENTS = 2\n",
        "N_CLUSTERS = 4\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "def load_embeddings_for_material(h5_path, material_key):\n",
        "    all_embeds = []\n",
        "    all_positions = []\n",
        "    with h5py.File(h5_path, 'r') as f:\n",
        "        for name in f.keys():\n",
        "            if material_key.lower() in name.lower():\n",
        "                emb = f[name][\"embeddings\"][:]\n",
        "                pos = f[name][\"positions\"][:]\n",
        "                all_embeds.append(emb)\n",
        "                all_positions.append(pos)\n",
        "    return np.vstack(all_embeds), np.vstack(all_positions)\n",
        "\n",
        "\n",
        "def run_dimensionality_reduction(embeddings, method='pca'):\n",
        "    if method == 'pca':\n",
        "        reducer = PCA(n_components=N_COMPONENTS)\n",
        "    elif method == 'tsne':\n",
        "        reducer = TSNE(n_components=N_COMPONENTS, perplexity=30, n_iter=500)\n",
        "    elif method == 'umap':\n",
        "        reducer = umap.UMAP(n_components=N_COMPONENTS)\n",
        "    else:\n",
        "        raise ValueError(\"Unknown reduction method\")\n",
        "    return reducer.fit_transform(embeddings)\n",
        "\n",
        "\n",
        "def run_clustering(embeddings, n_clusters=N_CLUSTERS):\n",
        "    model = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "    return model.fit_predict(embeddings)\n",
        "\n",
        "\n",
        "def plot_reduced(reduced, labels, title, filename):\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    scatter = plt.scatter(reduced[:, 0], reduced[:, 1], c=labels, cmap='tab10', s=5, alpha=0.7)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Component 1\")\n",
        "    plt.ylabel(\"Component 2\")\n",
        "    plt.colorbar(scatter)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(OUTPUT_DIR, filename))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(f\"Loading embeddings for material: {TARGET_MATERIAL}\")\n",
        "    emb, pos = load_embeddings_for_material(H5_PATH, TARGET_MATERIAL)\n",
        "\n",
        "    print(\"Reducing dimensions with PCA and UMAP...\")\n",
        "    reduced_pca = run_dimensionality_reduction(emb, method='pca')\n",
        "    reduced_umap = run_dimensionality_reduction(emb, method='umap')\n",
        "\n",
        "    print(\"Running K-means clustering...\")\n",
        "    cluster_labels = run_clustering(emb)\n",
        "\n",
        "    print(\"Plotting...\")\n",
        "    plot_reduced(reduced_pca, cluster_labels,\n",
        "                 title=f\"PCA Clusters - {TARGET_MATERIAL}\",\n",
        "                 filename=f\"{TARGET_MATERIAL}_pca_clusters.png\")\n",
        "\n",
        "    plot_reduced(reduced_umap, cluster_labels,\n",
        "                 title=f\"UMAP Clusters - {TARGET_MATERIAL}\",\n",
        "                 filename=f\"{TARGET_MATERIAL}_umap_clusters.png\")\n",
        "\n",
        "    print(\"Done.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import h5py\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "import umap\n",
        "import os\n",
        "\n",
        "# --- Load Embeddings ---\n",
        "EMBED_H5_PATH = \"dinov2_embeddings.h5\"\n",
        "SUBSTR_FILTER = \"SnSe\"  # <-- Change this to \"Graphene\" or \"MoS2\" etc.\n",
        "\n",
        "with h5py.File(EMBED_H5_PATH, 'r') as f:\n",
        "    all_keys = [k for k in f.keys() if SUBSTR_FILTER in k]\n",
        "    all_embeds = np.concatenate([f[k]['embeddings'][()] for k in all_keys])\n",
        "    all_positions = np.concatenate([f[k]['positions'][()] for k in all_keys])\n",
        "    img_shape = f[all_keys[0]]['image'].shape\n",
        "    img = f[all_keys[0]]['image'][()]\n",
        "\n",
        "# --- Dimensionality Reduction + Clustering ---\n",
        "reducer = umap.UMAP(n_components=2, random_state=42)\n",
        "umap_proj = reducer.fit_transform(all_embeds)\n",
        "\n",
        "kmeans = KMeans(n_clusters=4, random_state=0).fit(umap_proj)\n",
        "labels = kmeans.labels_\n",
        "\n",
        "# --- Plot ROIs on Original Image ---\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "ax.imshow(img, cmap='gray')\n",
        "for (y, x), label in zip(all_positions, labels):\n",
        "    rect = patches.Rectangle((x, y), PATCH_SIZE, PATCH_SIZE,\n",
        "                             linewidth=0.5, edgecolor=plt.cm.tab10(label), facecolor='none')\n",
        "    ax.add_patch(rect)\n",
        "ax.set_title(f\"Clusters mapped on image - {SUBSTR_FILTER}\")\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "output_dir = f\"patch_clusters_{SUBSTR_FILTER}\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for (y, x), label in zip(all_positions, labels):\n",
        "    patch = img[y:y+PATCH_SIZE, x:x+PATCH_SIZE]\n",
        "    fname = f\"{output_dir}/cluster{label}_{y}_{x}.png\"\n",
        "    Image.fromarray((patch * 255).astype(np.uint8)).save(fname)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import h5py\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from sklearn.cluster import KMeans\n",
        "from torchvision import transforms\n",
        "from dinov2.data.transforms import make_classification_eval_transform\n",
        "from skimage.feature import blob_log\n",
        "\n",
        "# === CONFIG ===\n",
        "h5_path = \"/home/gowthamnh/hackathon_gg/data/MoS2_Nanowire/kmr_doped/HAADF_4.h5\"  # Change this to the .h5 file\n",
        "PATCH_SIZE = 64\n",
        "DINO_RESIZE = 224\n",
        "N_CLUSTERS = 4\n",
        "BATCH_SIZE = 256\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "DINO_MODEL = \"dinov2_vitb14\"\n",
        "OUTPUT_H5 = \"atom_embeddings_individual.h5\"\n",
        "\n",
        "# === Load DINOv2 ===\n",
        "model = torch.hub.load(\"facebookresearch/dinov2\", DINO_MODEL).to(DEVICE).eval()\n",
        "transform = make_classification_eval_transform()\n",
        "\n",
        "def normalize_percentile(img, pmin=2, pmax=98):\n",
        "    lo, hi = np.percentile(img, (pmin, pmax))\n",
        "    return np.clip((img - lo) / (hi - lo), 0, 1)\n",
        "\n",
        "def extract_first_2d_dataset(g):\n",
        "    if isinstance(g, h5py.Dataset) and g.ndim >= 2:\n",
        "        arr = g[()]\n",
        "        while arr.ndim > 2:\n",
        "            arr = arr[arr.shape[0] // 2]\n",
        "        return np.squeeze(arr).astype(np.float32)\n",
        "    elif isinstance(g, h5py.Group):\n",
        "        for name in g:\n",
        "            try:\n",
        "                return extract_first_2d_dataset(g[name])\n",
        "            except Exception:\n",
        "                continue\n",
        "    raise ValueError(\"No valid 2D dataset found.\")\n",
        "\n",
        "def detect_atoms_log(img, min_sigma=1.5, max_sigma=3.5, threshold=0.02):\n",
        "    blobs = blob_log(img, min_sigma=min_sigma, max_sigma=max_sigma, threshold=threshold)\n",
        "    return [(int(y), int(x)) for y, x, _ in blobs]\n",
        "\n",
        "def crop_patch(img, coords):\n",
        "    patches, valid_coords = [], []\n",
        "    h, w = img.shape\n",
        "    half = PATCH_SIZE // 2\n",
        "    for (y, x) in coords:\n",
        "        if y - half < 0 or y + half > h or x - half < 0 or x + half > w:\n",
        "            continue\n",
        "        patch = img[y - half:y + half, x - half:x + half]\n",
        "        patch = cv2.resize(patch, (DINO_RESIZE, DINO_RESIZE), interpolation=cv2.INTER_CUBIC)\n",
        "        tensor = transform(Image.fromarray((patch * 255).astype(np.uint8)).convert(\"RGB\"))\n",
        "        patches.append(tensor)\n",
        "        valid_coords.append((y, x))\n",
        "    return patches, valid_coords\n",
        "\n",
        "# === Run processing ===\n",
        "fname = os.path.splitext(os.path.basename(h5_path))[0]\n",
        "with h5py.File(h5_path, 'r') as f_in:\n",
        "    img = extract_first_2d_dataset(f_in)\n",
        "    img = normalize_percentile(img)\n",
        "    print(f\"[PROCESSING] {h5_path} with shape {img.shape}\")\n",
        "\n",
        "    coords = detect_atoms_log(img)\n",
        "    if len(coords) == 0:\n",
        "        print(\"[SKIP] No atoms found.\")\n",
        "    else:\n",
        "        all_embeddings = []\n",
        "        all_coords = []\n",
        "        patch_batch, valid_coords = crop_patch(img, coords)\n",
        "\n",
        "        for i in range(0, len(patch_batch), BATCH_SIZE):\n",
        "            batch = torch.stack(patch_batch[i:i + BATCH_SIZE]).to(DEVICE)\n",
        "            with torch.no_grad():\n",
        "                feats = model.forward_features(batch)[\"x_norm_patchtokens\"]\n",
        "                emb = feats.mean(dim=1).cpu().numpy()\n",
        "            all_embeddings.append(emb)\n",
        "            all_coords.extend(valid_coords[i:i + BATCH_SIZE])\n",
        "\n",
        "        all_embeddings = np.vstack(all_embeddings)\n",
        "\n",
        "        with h5py.File(OUTPUT_H5, \"a\") as f_out:\n",
        "            group = f_out.require_group(fname)\n",
        "            group.create_dataset(\"embeddings\", data=all_embeddings)\n",
        "            group.create_dataset(\"coords\", data=np.array(all_coords))\n",
        "            group.create_dataset(\"image\", data=img.astype(np.float32))\n",
        "        print(f\"[âœ“] Saved {len(all_embeddings)} embeddings for {fname}\")\n",
        "\n",
        "        kmeans = KMeans(n_clusters=N_CLUSTERS, random_state=42)\n",
        "        labels = kmeans.fit_predict(all_embeddings)\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(8, 8))\n",
        "        ax.imshow(img, cmap=\"viridis\")\n",
        "        for (y, x), label in zip(all_coords, labels):\n",
        "            circ = patches.Circle((x, y), radius=4, color=plt.cm.tab10(label), fill=True, linewidth=0)\n",
        "            ax.add_patch(circ)\n",
        "        ax.set_title(f\"Clustered Atoms - {fname}\")\n",
        "        ax.axis(\"off\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset CdTe_STO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "from tifffile import imread\n",
        "\n",
        "# === Settings ===\n",
        "ROOT_DIR = \"/home/gowthamnh/hackathon_gg/data/image_data\"\n",
        "DATASETS = {\n",
        "    \"cdte_dataset.h5\": \"DataSet_CdTe\",\n",
        "    \"sto_dataset.h5\": \"DataSet_STO\"\n",
        "}\n",
        "N_PREVIEW = 5  # For visual inspection\n",
        "\n",
        "# === Utils ===\n",
        "def normalize_percentile(img, pmin=2, pmax=98):\n",
        "    lo, hi = np.percentile(img, (pmin, pmax))\n",
        "    return np.clip((img - lo) / (hi - lo), 0, 1)\n",
        "\n",
        "def extract_label(fname):\n",
        "    return os.path.basename(fname).split(\"_\")[0].lower()\n",
        "\n",
        "def find_all_tif_files(folder):\n",
        "    tif_files = []\n",
        "    for root, _, files in os.walk(folder):\n",
        "        for file in files:\n",
        "            if file.endswith(\".tif\"):\n",
        "                tif_files.append(os.path.join(root, file))\n",
        "    return tif_files\n",
        "\n",
        "# === Core Processing ===\n",
        "def process_dataset(out_h5, subfolder):\n",
        "    input_dir = os.path.join(ROOT_DIR, subfolder)\n",
        "    all_files = find_all_tif_files(input_dir)\n",
        "    print(f\"ðŸ“ Processing {subfolder} ({len(all_files)} images)\")\n",
        "\n",
        "    label_map = {}\n",
        "    key_list = []\n",
        "    previews = []\n",
        "\n",
        "    with h5py.File(out_h5, \"w\") as f:\n",
        "        image_group = f.create_group(\"images\")\n",
        "        label_ds = f.create_group(\"labels\")\n",
        "\n",
        "        for path in all_files:\n",
        "            try:\n",
        "                raw = imread(path)\n",
        "                if raw.ndim > 2:\n",
        "                    raw = raw[..., 0]\n",
        "                raw = np.squeeze(raw).astype(np.float32)\n",
        "                norm = normalize_percentile(raw)\n",
        "\n",
        "                fname = os.path.basename(path)\n",
        "                label = extract_label(fname)\n",
        "                key = os.path.splitext(fname)[0].lower()\n",
        "\n",
        "                # Avoid duplicates\n",
        "                if key in image_group:\n",
        "                    i = 1\n",
        "                    while f\"{key}_{i}\" in image_group:\n",
        "                        i += 1\n",
        "                    key = f\"{key}_{i}\"\n",
        "\n",
        "                image_group.create_dataset(key, data=norm, compression=\"gzip\")\n",
        "                label_ds.attrs[key] = label\n",
        "                key_list.append(key)\n",
        "\n",
        "                label_map[label] = label_map.get(label, 0) + 1\n",
        "\n",
        "                if len(previews) < N_PREVIEW:\n",
        "                    previews.append((raw, norm, label, fname))\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"[ERROR] {path}: {e}\")\n",
        "\n",
        "        f.create_dataset(\"image_keys\", data=np.array(key_list, dtype='S'))\n",
        "\n",
        "    print(f\"âœ… Saved to {out_h5}\")\n",
        "    print(\"ðŸ“Š Label summary:\", label_map)\n",
        "    return previews\n",
        "\n",
        "# === Plot ===\n",
        "def plot_previews(previews, title):\n",
        "    fig, axs = plt.subplots(len(previews), 2, figsize=(6, 2 * len(previews)))\n",
        "    for i, (raw, norm, label, fname) in enumerate(previews):\n",
        "        axs[i, 0].imshow(raw, cmap='gray')\n",
        "        axs[i, 0].set_title(f\"Original - {fname}\")\n",
        "        axs[i, 1].imshow(norm, cmap='gray')\n",
        "        axs[i, 1].set_title(f\"Normalized - label: {label}\")\n",
        "    fig.suptitle(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# === Execute ===\n",
        "for out_file, folder in DATASETS.items():\n",
        "    previews = process_dataset(out_file, folder)\n",
        "    plot_previews(previews, f\"Preview from {out_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import h5py\n",
        "from skimage.feature import blob_log\n",
        "from skimage.filters import gaussian\n",
        "from skimage import exposure\n",
        "import random\n",
        "\n",
        "# === Parameters ===\n",
        "H5_PATH = \"cdte_dataset.h5\"  # or \"sto_dataset.h5\"\n",
        "N_SAMPLES = 3\n",
        "PATCH_SIZE = 64\n",
        "\n",
        "# === Processing Functions ===\n",
        "\n",
        "def normalize_percentile(img, pmin=2, pmax=98):\n",
        "    lo, hi = np.percentile(img, (pmin, pmax))\n",
        "    return np.clip((img - lo) / (hi - lo), 0, 1)\n",
        "\n",
        "def enhance_contrast(img):\n",
        "    return exposure.equalize_adapthist(img, clip_limit=0.03)\n",
        "\n",
        "def preprocess_for_atom_detection(img):\n",
        "    img_norm = normalize_percentile(img)\n",
        "    img_smooth = gaussian(img_norm, sigma=1)\n",
        "    img_enhanced = enhance_contrast(img_smooth)\n",
        "    return img_enhanced\n",
        "\n",
        "def detect_atoms_log(img, min_sigma=1.2, max_sigma=2.5, threshold=0.02):\n",
        "    blobs = blob_log(img, min_sigma=min_sigma, max_sigma=max_sigma, threshold=threshold)\n",
        "    return [(int(y), int(x)) for y, x, _ in blobs]\n",
        "\n",
        "def extract_patches(norm_img, coords, patch_size=64, max_patches=3):\n",
        "    patches = []\n",
        "    h, w = norm_img.shape\n",
        "    for (y, x) in coords[:max_patches]:\n",
        "        y1 = max(y - patch_size // 2, 0)\n",
        "        y2 = min(y + patch_size // 2, h)\n",
        "        x1 = max(x - patch_size // 2, 0)\n",
        "        x2 = min(x + patch_size // 2, w)\n",
        "        patch = norm_img[y1:y2, x1:x2]\n",
        "        if patch.shape == (patch_size, patch_size):\n",
        "            patches.append(patch)\n",
        "    return patches\n",
        "\n",
        "# === Collage Visualization ===\n",
        "\n",
        "def show_collage(img, norm, coords, patches, label, title):\n",
        "    circle_img = np.stack([norm]*3, axis=-1)\n",
        "    for (y, x) in coords:\n",
        "        cv2.circle(circle_img, (x, y), 4, (1.0, 0.0, 0.0), 1)\n",
        "\n",
        "    fig, axs = plt.subplots(2, 3, figsize=(10, 6))\n",
        "    axs[0, 0].imshow(img, cmap='gray'); axs[0, 0].set_title(\"Original\")\n",
        "    axs[0, 1].imshow(norm, cmap='gray'); axs[0, 1].set_title(\"Normalized\")\n",
        "    axs[0, 2].imshow(circle_img); axs[0, 2].set_title(\"Atoms Detected\")\n",
        "\n",
        "    for i, patch in enumerate(patches[:3]):\n",
        "        axs[1, i].imshow(patch, cmap='gray')\n",
        "        axs[1, i].set_title(f\"Patch {i+1}\")\n",
        "        axs[1, i].axis('off')\n",
        "\n",
        "    plt.suptitle(f\"{title} â€” Label: {label}\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# === Run Over H5 ===\n",
        "\n",
        "def run_visual_pipeline(h5_file, n_samples=3):\n",
        "    with h5py.File(h5_file, 'r') as f:\n",
        "        image_group = f[\"images\"]\n",
        "        labels = dict(f[\"labels\"].attrs)\n",
        "        all_keys = list(image_group.keys())\n",
        "\n",
        "        # Invert label map to {label: [keys]}\n",
        "        label_to_keys = {}\n",
        "        for k, v in labels.items():\n",
        "            label = v.decode(\"utf-8\") if isinstance(v, bytes) else v\n",
        "            label_to_keys.setdefault(label, []).append(k)\n",
        "\n",
        "        print(f\"ðŸ“Š Labels found: {list(label_to_keys.keys())}\")\n",
        "\n",
        "        for label, keys in label_to_keys.items():\n",
        "            sample_keys = random.sample(keys, min(len(keys), n_samples))\n",
        "            for key in sample_keys:\n",
        "                img = image_group[key][()]\n",
        "                norm = preprocess_for_atom_detection(img)\n",
        "                coords = detect_atoms_log(norm)\n",
        "                patches = extract_patches(norm, coords, PATCH_SIZE)\n",
        "                show_collage(img, norm, coords, patches, label, key)\n",
        "\n",
        "# === Example Run ===\n",
        "# run_visual_pipeline(\"cdte_dataset.h5\", n_samples=3)\n",
        "run_visual_pipeline(\"sto_dataset.h5\", n_samples=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8.1\n"
          ]
        }
      ],
      "source": [
        "import atomai\n",
        "print(atomai.__version__)\n",
        "from atomai.models import *  # this should now work\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Graphene  image_data  Mos2_monolayer  MoS2_Nanowire  SnSe\n"
          ]
        }
      ],
      "source": [
        "!ls data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/home/gowthamnh/hackathon_gg'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyO2ZH6U5ktfe5cHj3mMTxQC",
      "include_colab_link": true,
      "provenance": [],
      "runtime_attributes": {
        "runtime_version": "2025.07"
      }
    },
    "kernelspec": {
      "display_name": "mic_hack_gg",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
